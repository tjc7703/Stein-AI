"""
ğŸ“ˆ Stein AI - ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
í•™ìŠµ íŒ¨í„´ ë¶„ì„ ë° ë¯¸ë˜ ì„±ëŠ¥ ì˜ˆì¸¡ ì—”ì§„
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from pathlib import Path
import logging
import json
import pickle

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, classification_report, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼ êµ¬ì¡°"""
    metric_name: str
    current_value: float
    predicted_value: float
    confidence: float
    prediction_horizon: str  # "1ì¼", "1ì£¼", "1ê°œì›”"
    improvement_probability: float
    trend_direction: str  # "ìƒìŠ¹", "í•˜ë½", "ì•ˆì •"
    key_factors: List[str]

@dataclass
class LearningPattern:
    """í•™ìŠµ íŒ¨í„´ êµ¬ì¡°"""
    user_id: str
    pattern_type: str  # "ì‹œê°„ëŒ€", "ì£¼ì œ", "ë‚œì´ë„" ë“±
    pattern_data: Dict[str, Any]
    frequency: int
    effectiveness_score: float
    last_updated: datetime

class MLPredictionEngine:
    """ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡ ì—”ì§„"""
    
    def __init__(self, model_dir: str = "data/ml_models"):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥ì†Œ
        self.models = {
            'performance_predictor': None,
            'satisfaction_classifier': None,
            'pattern_clusterer': None,
            'trend_analyzer': None
        }
        
        # ë°ì´í„° ì „ì²˜ë¦¬ê¸°
        self.scalers = {
            'features': StandardScaler(),
            'targets': StandardScaler()
        }
        
        self.label_encoders = {}
        
        # í•™ìŠµ íŒ¨í„´ ì €ì¥ì†Œ
        self.learning_patterns = []
        
        logger.info("ğŸ¤– ML ì˜ˆì¸¡ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

    def prepare_training_data(self, feedback_data: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬"""
        try:
            if not feedback_data:
                logger.warning("í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return np.array([]), np.array([])
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(feedback_data)
            
            # ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df['hour'] = df['timestamp'].dt.hour
            df['day_of_week'] = df['timestamp'].dt.dayofweek
            df['day_of_month'] = df['timestamp'].dt.day
            
            # í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ
            df['question_length'] = df['question'].str.len()
            df['response_length'] = df['response'].str.len()
            df['has_code'] = df['question'].str.contains(r'```|def |class |import ', regex=True)
            df['question_marks'] = df['question'].str.count(r'\?')
            df['exclamation_marks'] = df['question'].str.count(r'!')
            
            # ì‚¬ìš©ì í–‰ë™ íŠ¹ì„±
            df['response_efficiency'] = df['response_length'] / (df['response_time'] + 1)
            df['quality_to_rating_ratio'] = df['quality_score'] / (df['rating'] + 0.1)
            
            # íŠ¹ì„± ì„ íƒ
            feature_columns = [
                'hour', 'day_of_week', 'day_of_month',
                'question_length', 'response_length', 'has_code',
                'question_marks', 'exclamation_marks',
                'response_time', 'quality_score',
                'response_efficiency', 'quality_to_rating_ratio'
            ]
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            for col in feature_columns:
                if col in df.columns:
                    df[col] = df[col].fillna(df[col].mean() if df[col].dtype in ['int64', 'float64'] else 0)
            
            # íŠ¹ì„± ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
            X = df[feature_columns].values
            y = df['rating'].values
            
            # ë°ì´í„° ì •ê·œí™”
            X_scaled = self.scalers['features'].fit_transform(X)
            
            return X_scaled, y
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return np.array([]), np.array([])

    def train_performance_predictor(self, feedback_data: List[Dict]) -> Dict[str, float]:
        """ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
        try:
            X, y = self.prepare_training_data(feedback_data)
            
            if len(X) < 5:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ëŸ‰
                logger.warning("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
                return {"accuracy": 0.0, "mse": 0.0}
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ í•™ìŠµ
            self.models['performance_predictor'] = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            self.models['performance_predictor'].fit(X_train, y_train)
            
            # ëª¨ë¸ í‰ê°€
            y_pred = self.models['performance_predictor'].predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            
            # êµì°¨ ê²€ì¦
            cv_scores = cross_val_score(
                self.models['performance_predictor'], X, y, 
                cv=min(5, len(X)//2), scoring='neg_mean_squared_error'
            )
            
            accuracy = 1 - np.sqrt(-cv_scores.mean()) / 5.0  # 5ì  ì²™ë„ ê¸°ì¤€
            
            # ëª¨ë¸ ì €ì¥
            self._save_model('performance_predictor')
            
            logger.info(f"ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - ì •í™•ë„: {accuracy:.3f}")
            
            return {
                "accuracy": float(accuracy),
                "mse": float(mse),
                "cv_mean": float(-cv_scores.mean()),
                "cv_std": float(cv_scores.std())
            }
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"accuracy": 0.0, "mse": float('inf')}

    def train_satisfaction_classifier(self, feedback_data: List[Dict]) -> Dict[str, float]:
        """ë§Œì¡±ë„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ"""
        try:
            X, y = self.prepare_training_data(feedback_data)
            
            if len(X) < 5:
                return {"accuracy": 0.0}
            
            # ë§Œì¡±ë„ë¥¼ 3ë‹¨ê³„ë¡œ ë¶„ë¥˜ (1-2: ë‚®ìŒ, 3: ë³´í†µ, 4-5: ë†’ìŒ)
            y_categorical = np.where(y <= 2, 0, np.where(y <= 3, 1, 2))
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical
            )
            
            # ê·¸ë¼ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë¶„ë¥˜ê¸° í•™ìŠµ
            self.models['satisfaction_classifier'] = GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            
            self.models['satisfaction_classifier'].fit(X_train, y_train)
            
            # ëª¨ë¸ í‰ê°€
            y_pred = self.models['satisfaction_classifier'].predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            
            # ëª¨ë¸ ì €ì¥
            self._save_model('satisfaction_classifier')
            
            logger.info(f"ë§Œì¡±ë„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - ì •í™•ë„: {accuracy:.3f}")
            
            return {"accuracy": float(accuracy)}
            
        except Exception as e:
            logger.error(f"ë§Œì¡±ë„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"accuracy": 0.0}

    def train_pattern_clusterer(self, feedback_data: List[Dict]) -> Dict[str, Any]:
        """í•™ìŠµ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ í•™ìŠµ"""
        try:
            X, _ = self.prepare_training_data(feedback_data)
            
            if len(X) < 3:
                return {"clusters": 0, "inertia": float('inf')}
            
            # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (ì—˜ë³´ìš° ë°©ë²• ê°„ì†Œí™”)
            max_clusters = min(5, len(X) // 2)
            inertias = []
            
            for k in range(1, max_clusters + 1):
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(X)
                inertias.append(kmeans.inertia_)
            
            # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            optimal_k = min(3, max_clusters)
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            self.models['pattern_clusterer'] = KMeans(
                n_clusters=optimal_k, 
                random_state=42, 
                n_init=10
            )
            
            cluster_labels = self.models['pattern_clusterer'].fit_predict(X)
            
            # í´ëŸ¬ìŠ¤í„° ë¶„ì„
            cluster_info = {}
            for i in range(optimal_k):
                mask = cluster_labels == i
                if np.sum(mask) > 0:
                    cluster_info[f"cluster_{i}"] = {
                        "size": int(np.sum(mask)),
                        "centroid": self.models['pattern_clusterer'].cluster_centers_[i].tolist()
                    }
            
            # ëª¨ë¸ ì €ì¥
            self._save_model('pattern_clusterer')
            
            logger.info(f"íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ - {optimal_k}ê°œ í´ëŸ¬ìŠ¤í„°")
            
            return {
                "clusters": optimal_k,
                "inertia": float(self.models['pattern_clusterer'].inertia_),
                "cluster_info": cluster_info
            }
            
        except Exception as e:
            logger.error(f"íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
            return {"clusters": 0, "inertia": float('inf')}

    def predict_future_performance(self, current_features: Dict[str, Any], 
                                 horizon_days: int = 7) -> List[PredictionResult]:
        """ë¯¸ë˜ ì„±ëŠ¥ ì˜ˆì¸¡"""
        try:
            predictions = []
            
            if self.models['performance_predictor'] is None:
                logger.warning("ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return predictions
            
            # í˜„ì¬ íŠ¹ì„±ì„ ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
            feature_vector = self._extract_features_from_dict(current_features)
            feature_vector_scaled = self.scalers['features'].transform([feature_vector])
            
            # ê¸°ë³¸ ì˜ˆì¸¡
            base_prediction = self.models['performance_predictor'].predict(feature_vector_scaled)[0]
            
            # ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ (1ì¼, 1ì£¼, 1ê°œì›”)
            horizons = [
                (1, "1ì¼"),
                (7, "1ì£¼"), 
                (30, "1ê°œì›”")
            ]
            
            for days, label in horizons:
                # ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ íŠ¹ì„± ë³€í™” ì‹œë®¬ë ˆì´ì…˜
                future_features = feature_vector.copy()
                
                # í•™ìŠµ íš¨ê³¼ ë°˜ì˜ (ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ê°œì„ )
                learning_factor = 1 + (days * 0.01)  # 1% per day
                future_features[3] *= learning_factor  # ì§ˆë¬¸ í’ˆì§ˆ ê°œì„ 
                
                # íŠ¹ì„± ì •ê·œí™”
                future_features_scaled = self.scalers['features'].transform([future_features])
                
                # ì˜ˆì¸¡ ì‹¤í–‰
                predicted_rating = self.models['performance_predictor'].predict(future_features_scaled)[0]
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ì•™ìƒë¸” ì˜ˆì¸¡ì˜ ë¶„ì‚° ê¸°ë°˜)
                if hasattr(self.models['performance_predictor'], 'estimators_'):
                    predictions_ensemble = [
                        estimator.predict(future_features_scaled)[0] 
                        for estimator in self.models['performance_predictor'].estimators_[:10]
                    ]
                    confidence = 1.0 - (np.std(predictions_ensemble) / 5.0)
                else:
                    confidence = 0.7  # ê¸°ë³¸ê°’
                
                # ê°œì„  í™•ë¥  ê³„ì‚°
                improvement_prob = max(0.0, min(1.0, (predicted_rating - base_prediction + 2) / 4))
                
                # íŠ¸ë Œë“œ ë°©í–¥
                if predicted_rating > base_prediction + 0.1:
                    trend = "ìƒìŠ¹"
                elif predicted_rating < base_prediction - 0.1:
                    trend = "í•˜ë½"
                else:
                    trend = "ì•ˆì •"
                
                # ì£¼ìš” ì˜í–¥ ìš”ì¸ (íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜)
                if hasattr(self.models['performance_predictor'], 'feature_importances_'):
                    feature_names = [
                        'hour', 'day_of_week', 'day_of_month',
                        'question_length', 'response_length', 'has_code',
                        'question_marks', 'exclamation_marks',
                        'response_time', 'quality_score',
                        'response_efficiency', 'quality_to_rating_ratio'
                    ]
                    
                    importances = self.models['performance_predictor'].feature_importances_
                    top_factors = [
                        feature_names[i] for i in np.argsort(importances)[-3:][::-1]
                    ]
                else:
                    top_factors = ["ì§ˆë¬¸_í’ˆì§ˆ", "ì‘ë‹µ_ì‹œê°„", "í•™ìŠµ_íŒ¨í„´"]
                
                prediction = PredictionResult(
                    metric_name=f"ì˜ˆìƒ_ë§Œì¡±ë„_{label}",
                    current_value=float(base_prediction),
                    predicted_value=float(predicted_rating),
                    confidence=float(max(0.0, min(1.0, confidence))),
                    prediction_horizon=label,
                    improvement_probability=float(improvement_prob),
                    trend_direction=trend,
                    key_factors=top_factors
                )
                
                predictions.append(prediction)
            
            return predictions
            
        except Exception as e:
            logger.error(f"ë¯¸ë˜ ì„±ëŠ¥ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return []

    def analyze_learning_patterns(self, feedback_data: List[Dict]) -> Dict[str, Any]:
        """í•™ìŠµ íŒ¨í„´ ì¢…í•© ë¶„ì„"""
        try:
            if not feedback_data:
                return {"patterns": [], "insights": []}
            
            df = pd.DataFrame(feedback_data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            patterns = {}
            
            # 1. ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
            df['hour'] = df['timestamp'].dt.hour
            hourly_performance = df.groupby('hour')['rating'].mean()
            best_hours = hourly_performance.nlargest(3).index.tolist()
            
            patterns['time_pattern'] = {
                "type": "ì‹œê°„ëŒ€ë³„_ì„±ëŠ¥",
                "best_hours": [int(h) for h in best_hours],
                "performance_by_hour": hourly_performance.to_dict(),
                "insight": f"ê°€ì¥ ì¢‹ì€ ì„±ê³¼ë¥¼ ë‚´ëŠ” ì‹œê°„: {', '.join([f'{h}ì‹œ' for h in best_hours])}"
            }
            
            # 2. ì£¼ì œë³„ íŒ¨í„´ ë¶„ì„
            df['has_code'] = df['question'].str.contains(r'```|def |class |import ', regex=True)
            df['is_conceptual'] = df['question'].str.contains(r'ê°œë…|ì´ë¡ |ì›ë¦¬|ê°œë…|ì„¤ëª…', regex=True)
            df['is_troubleshooting'] = df['question'].str.contains(r'ì˜¤ë¥˜|ì—ëŸ¬|ë¬¸ì œ|ì˜¤ë¥˜|ë””ë²„ê¹…', regex=True)
            
            topic_performance = {
                "ì½”ë”©": df[df['has_code']]['rating'].mean() if df['has_code'].any() else 0,
                "ê°œë…": df[df['is_conceptual']]['rating'].mean() if df['is_conceptual'].any() else 0,
                "ë¬¸ì œí•´ê²°": df[df['is_troubleshooting']]['rating'].mean() if df['is_troubleshooting'].any() else 0
            }
            
            best_topic = max(topic_performance.items(), key=lambda x: x[1])
            
            patterns['topic_pattern'] = {
                "type": "ì£¼ì œë³„_ì„±ëŠ¥",
                "performance_by_topic": topic_performance,
                "strongest_area": best_topic[0],
                "insight": f"ê°€ì¥ ê°•í•œ ì˜ì—­: {best_topic[0]} (í‰ì  {best_topic[1]:.1f})"
            }
            
            # 3. í•™ìŠµ ì§„í™” íŒ¨í„´
            df_sorted = df.sort_values('timestamp')
            df_sorted['rolling_avg'] = df_sorted['rating'].rolling(window=5, min_periods=1).mean()
            
            recent_avg = df_sorted['rolling_avg'].tail(5).mean()
            early_avg = df_sorted['rolling_avg'].head(5).mean()
            improvement_rate = (recent_avg - early_avg) / max(early_avg, 0.1)
            
            patterns['evolution_pattern'] = {
                "type": "í•™ìŠµ_ì§„í™”",
                "improvement_rate": float(improvement_rate),
                "recent_performance": float(recent_avg),
                "early_performance": float(early_avg),
                "insight": f"í•™ìŠµ ì§„í™”ìœ¨: {improvement_rate*100:.1f}% {'ê°œì„ ' if improvement_rate > 0 else 'ì•ˆì •'}"
            }
            
            # ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = [
                f"ğŸ“ˆ ì „ì²´ í•™ìŠµ ì„¸ì…˜: {len(df)}íšŒ",
                f"â­ í‰ê·  ë§Œì¡±ë„: {df['rating'].mean():.1f}/5.0",
                f"ğŸ¯ {patterns['topic_pattern']['strongest_area']} ì˜ì—­ì—ì„œ ë›°ì–´ë‚¨",
                f"â° {patterns['time_pattern']['best_hours'][0]}ì‹œ ê²½ì— ìµœê³  ì„±ê³¼",
                f"ğŸ“Š ì§€ì†ì ì¸ {'ê°œì„ ' if improvement_rate > 0.05 else 'ì•ˆì •ì  ì„±ê³¼'} ì¶”ì„¸"
            ]
            
            return {
                "patterns": patterns,
                "insights": insights,
                "total_sessions": len(df),
                "average_rating": float(df['rating'].mean()),
                "improvement_trend": "positive" if improvement_rate > 0.05 else "stable"
            }
            
        except Exception as e:
            logger.error(f"í•™ìŠµ íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"patterns": {}, "insights": []}

    def get_ai_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """AI ê¸°ë°˜ ê°œì„  ì¶”ì²œ"""
        try:
            recommendations = []
            
            if 'patterns' in analysis_results:
                patterns = analysis_results['patterns']
                
                # ì‹œê°„ëŒ€ ìµœì í™” ì¶”ì²œ
                if 'time_pattern' in patterns:
                    best_hours = patterns['time_pattern']['best_hours']
                    recommendations.append(
                        f"ğŸ•’ ìµœì  í•™ìŠµ ì‹œê°„: {', '.join([f'{h}ì‹œ' for h in best_hours[:2]])}ì— ì¤‘ìš”í•œ í•™ìŠµ ì„¸ì…˜ì„ ë°°ì¹˜í•˜ì„¸ìš”"
                    )
                
                # ì£¼ì œë³„ ê°•í™” ì¶”ì²œ
                if 'topic_pattern' in patterns:
                    strongest = patterns['topic_pattern']['strongest_area']
                    recommendations.append(
                        f"ğŸ’ª ê°•ì  í™œìš©: {strongest} ì˜ì—­ì˜ ì¥ì ì„ ë‹¤ë¥¸ ì˜ì—­ì—ë„ ì ìš©í•´ë³´ì„¸ìš”"
                    )
                
                # í•™ìŠµ ì§„í™” ê¸°ë°˜ ì¶”ì²œ
                if 'evolution_pattern' in patterns:
                    improvement_rate = patterns['evolution_pattern']['improvement_rate']
                    if improvement_rate > 0.1:
                        recommendations.append("ğŸš€ í›Œë¥­í•œ ì„±ì¥ì„¸! í˜„ì¬ í•™ìŠµ ë°©ì‹ì„ ìœ ì§€í•˜ì„¸ìš”")
                    elif improvement_rate < -0.05:
                        recommendations.append("ğŸ”„ í•™ìŠµ ë°©ì‹ ë³€í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                    else:
                        recommendations.append("ğŸ“ˆ ì•ˆì •ì  ì„±ê³¼! ìƒˆë¡œìš´ ë„ì „ì„ ì‹œë„í•´ë³´ì„¸ìš”")
            
            # ì¼ë°˜ì ì¸ AI ì¶”ì²œ
            recommendations.extend([
                "ğŸ¯ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ğŸ“š ì •ê¸°ì ì¸ í”¼ë“œë°± ì œê³µìœ¼ë¡œ AI ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•˜ì„¸ìš”",
                "ğŸ§  ë‹¤ì–‘í•œ ì£¼ì œë¡œ ì§ˆë¬¸í•˜ì—¬ AIì˜ í•™ìŠµ ë²”ìœ„ë¥¼ í™•ì¥í•˜ì„¸ìš”"
            ])
            
            return recommendations[:5]  # ìµœëŒ€ 5ê°œ ì¶”ì²œ
            
        except Exception as e:
            logger.error(f"AI ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return ["ğŸ¤– AIê°€ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ ì¶”ì²œì„ ì œê³µí•  ì˜ˆì •ì…ë‹ˆë‹¤"]

    def _extract_features_from_dict(self, feature_dict: Dict[str, Any]) -> List[float]:
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ íŠ¹ì„± ë²¡í„° ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ê°’ ì„¤ì •
            now = datetime.now()
            
            features = [
                feature_dict.get('hour', now.hour),
                feature_dict.get('day_of_week', now.weekday()),
                feature_dict.get('day_of_month', now.day),
                feature_dict.get('question_length', 100),
                feature_dict.get('response_length', 500),
                1 if feature_dict.get('has_code', False) else 0,
                feature_dict.get('question_marks', 1),
                feature_dict.get('exclamation_marks', 0),
                feature_dict.get('response_time', 3.0),
                feature_dict.get('quality_score', 7.0),
                feature_dict.get('response_efficiency', 166.7),
                feature_dict.get('quality_to_rating_ratio', 1.75)
            ]
            
            return features
            
        except Exception as e:
            logger.error(f"íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [0.0] * 12  # ê¸°ë³¸ íŠ¹ì„± ë²¡í„°

    def _save_model(self, model_name: str):
        """ëª¨ë¸ ì €ì¥"""
        try:
            if model_name in self.models and self.models[model_name] is not None:
                model_path = self.model_dir / f"{model_name}.pkl"
                with open(model_path, 'wb') as f:
                    pickle.dump(self.models[model_name], f)
                logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_name}")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨ {model_name}: {e}")

    def _load_model(self, model_name: str):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            model_path = self.model_dir / f"{model_name}.pkl"
            if model_path.exists():
                with open(model_path, 'rb') as f:
                    self.models[model_name] = pickle.load(f)
                logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
                return True
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
        return False

    def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ í™•ì¸"""
        status = {}
        for model_name in self.models:
            status[model_name] = {
                "trained": self.models[model_name] is not None,
                "file_exists": (self.model_dir / f"{model_name}.pkl").exists()
            }
        return status

# ì „ì—­ ML ì˜ˆì¸¡ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
ml_prediction_engine = MLPredictionEngine()

# í¸ì˜ í•¨ìˆ˜ë“¤
async def train_all_models(feedback_data: List[Dict]) -> Dict[str, Any]:
    """ëª¨ë“  ML ëª¨ë¸ í•™ìŠµ"""
    try:
        if not feedback_data:
            return {"error": "í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        results = {}
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
        perf_result = ml_prediction_engine.train_performance_predictor(feedback_data)
        results['performance_predictor'] = perf_result
        
        # ë§Œì¡±ë„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
        sat_result = ml_prediction_engine.train_satisfaction_classifier(feedback_data)
        results['satisfaction_classifier'] = sat_result
        
        # íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ í•™ìŠµ
        cluster_result = ml_prediction_engine.train_pattern_clusterer(feedback_data)
        results['pattern_clusterer'] = cluster_result
        
        # ì „ì²´ ì„±ê³µ ì—¬ë¶€
        results['overall_success'] = all([
            perf_result.get('accuracy', 0) > 0.3,
            sat_result.get('accuracy', 0) > 0.3,
            cluster_result.get('clusters', 0) > 0
        ])
        
        return results
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

async def get_performance_predictions(current_state: Dict[str, Any]) -> List[PredictionResult]:
    """ì„±ëŠ¥ ì˜ˆì¸¡ ìˆ˜í–‰"""
    return ml_prediction_engine.predict_future_performance(current_state)

async def analyze_learning_insights(feedback_data: List[Dict]) -> Dict[str, Any]:
    """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ë¶„ì„"""
    analysis = ml_prediction_engine.analyze_learning_patterns(feedback_data)
    recommendations = ml_prediction_engine.get_ai_recommendations(analysis)
    
    return {
        **analysis,
        "ai_recommendations": recommendations
    }

def get_ml_system_status() -> Dict[str, Any]:
    """ML ì‹œìŠ¤í…œ ìƒíƒœ"""
    return ml_prediction_engine.get_model_status() 