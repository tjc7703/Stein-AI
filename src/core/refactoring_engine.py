import ast
import re
import os
from typing import Dict, List, Any, Optional, Tuple, Set
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import json
import inspect

class RefactoringType(Enum):
    """ë¦¬íŒ©í† ë§ ìœ í˜•"""
    EXTRACT_METHOD = "extract_method"
    EXTRACT_CLASS = "extract_class"
    RENAME_VARIABLE = "rename_variable"
    REMOVE_DUPLICATION = "remove_duplication"
    SIMPLIFY_CONDITIONAL = "simplify_conditional"
    OPTIMIZE_IMPORTS = "optimize_imports"
    APPLY_DESIGN_PATTERN = "apply_design_pattern"
    IMPROVE_NAMING = "improve_naming"
    REDUCE_COMPLEXITY = "reduce_complexity"
    OPTIMIZE_PERFORMANCE = "optimize_performance"

class RefactoringPriority(Enum):
    """ë¦¬íŒ©í† ë§ ìš°ì„ ìˆœìœ„"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

@dataclass
class RefactoringOpportunity:
    """ë¦¬íŒ©í† ë§ ê¸°íšŒ"""
    refactoring_type: RefactoringType
    priority: RefactoringPriority
    description: str
    file_path: str
    line_start: int
    line_end: int
    estimated_effort: int  # ì‹œê°„ (ë¶„)
    potential_benefit: str
    code_snippet: str
    suggested_solution: str
    auto_applicable: bool

@dataclass
class RefactoringResult:
    """ë¦¬íŒ©í† ë§ ê²°ê³¼"""
    success: bool
    refactoring_type: RefactoringType
    changes_made: List[str]
    files_modified: List[str]
    metrics_before: Dict[str, Any]
    metrics_after: Dict[str, Any]
    improvement_summary: str

class RefactoringEngine:
    """ğŸ”§ ìµœê³  ìˆ˜ì¤€ì˜ ë¦¬íŒ©í† ë§ ì—”ì§„"""
    
    def __init__(self):
        self.refactoring_history = []
        self.design_patterns = self._load_design_patterns()
        self.naming_conventions = self._load_naming_conventions()
        self.performance_patterns = self._load_performance_patterns()
        
    def analyze_refactoring_opportunities(self, file_path: str) -> List[RefactoringOpportunity]:
        """ğŸ” ë¦¬íŒ©í† ë§ ê¸°íšŒ ë¶„ì„"""
        
        opportunities = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            # AST ìƒì„±
            tree = ast.parse(code)
            
            # ë‹¤ì–‘í•œ ë¦¬íŒ©í† ë§ ê¸°íšŒ ë¶„ì„
            opportunities.extend(self._analyze_method_extraction(tree, code, file_path))
            opportunities.extend(self._analyze_class_extraction(tree, code, file_path))
            opportunities.extend(self._analyze_code_duplication(tree, code, file_path))
            opportunities.extend(self._analyze_conditional_complexity(tree, code, file_path))
            opportunities.extend(self._analyze_naming_issues(tree, code, file_path))
            opportunities.extend(self._analyze_performance_issues(tree, code, file_path))
            opportunities.extend(self._analyze_import_optimization(tree, code, file_path))
            opportunities.extend(self._analyze_design_pattern_opportunities(tree, code, file_path))
            
            # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
            opportunities.sort(key=lambda x: self._get_priority_score(x.priority), reverse=True)
            
        except Exception as e:
            print(f"ë¦¬íŒ©í† ë§ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        return opportunities
    
    def _analyze_method_extraction(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ë©”ì„œë“œ ì¶”ì¶œ ê¸°íšŒ ë¶„ì„"""
        opportunities = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # í•¨ìˆ˜ê°€ ë„ˆë¬´ ê¸´ ê²½ìš°
                if len(node.body) > 20:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.EXTRACT_METHOD,
                        priority=RefactoringPriority.HIGH,
                        description=f"í•¨ìˆ˜ '{node.name}'ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(node.body)} ë¼ì¸)",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=30,
                        potential_benefit="ê°€ë…ì„± í–¥ìƒ, ì¬ì‚¬ìš©ì„± ì¦ëŒ€",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="í•¨ìˆ˜ë¥¼ ë…¼ë¦¬ì  ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í•¨ìˆ˜ë¡œ ë‚˜ëˆ„ì„¸ìš”.",
                        auto_applicable=False
                    ))
                
                # ë³µì¡í•œ ì¤‘ì²© êµ¬ì¡° ê²€ì‚¬
                nested_depth = self._calculate_nesting_depth(node)
                if nested_depth > 3:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.EXTRACT_METHOD,
                        priority=RefactoringPriority.MEDIUM,
                        description=f"í•¨ìˆ˜ '{node.name}'ì˜ ì¤‘ì²© êµ¬ì¡°ê°€ ë³µì¡í•©ë‹ˆë‹¤ (ê¹Šì´: {nested_depth})",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=45,
                        potential_benefit="ì½”ë“œ ë³µì¡ë„ ê°ì†Œ, ì´í•´ë„ í–¥ìƒ",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="ì¤‘ì²©ëœ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.",
                        auto_applicable=False
                    ))
        
        return opportunities
    
    def _analyze_class_extraction(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """í´ë˜ìŠ¤ ì¶”ì¶œ ê¸°íšŒ ë¶„ì„"""
        opportunities = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # í´ë˜ìŠ¤ê°€ ë„ˆë¬´ ë§ì€ ì±…ì„ì„ ê°€ì§€ëŠ” ê²½ìš°
                method_count = len([n for n in node.body if isinstance(n, ast.FunctionDef)])
                if method_count > 15:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.EXTRACT_CLASS,
                        priority=RefactoringPriority.HIGH,
                        description=f"í´ë˜ìŠ¤ '{node.name}'ì´ ë„ˆë¬´ ë§ì€ ë©”ì„œë“œë¥¼ ê°€ì§‘ë‹ˆë‹¤ ({method_count}ê°œ)",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=60,
                        potential_benefit="ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì¤€ìˆ˜, ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="ê´€ë ¨ ë©”ì„œë“œë“¤ì„ ê·¸ë£¹í•‘í•˜ì—¬ ë³„ë„ í´ë˜ìŠ¤ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.",
                        auto_applicable=False
                    ))
        
        return opportunities
    
    def _analyze_code_duplication(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ì½”ë“œ ì¤‘ë³µ ë¶„ì„"""
        opportunities = []
        
        # í•¨ìˆ˜ ê°„ ìœ ì‚¬ì„± ê²€ì‚¬
        functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
        
        for i, func1 in enumerate(functions):
            for func2 in functions[i+1:]:
                similarity = self._calculate_similarity(func1, func2)
                
                if similarity > 0.7:  # 70% ì´ìƒ ìœ ì‚¬
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.REMOVE_DUPLICATION,
                        priority=RefactoringPriority.HIGH,
                        description=f"í•¨ìˆ˜ '{func1.name}'ê³¼ '{func2.name}'ì´ ìœ ì‚¬í•©ë‹ˆë‹¤ ({similarity*100:.1f}%)",
                        file_path=file_path,
                        line_start=func1.lineno,
                        line_end=func2.end_lineno or func2.lineno,
                        estimated_effort=45,
                        potential_benefit="ì½”ë“œ ì¤‘ë³µ ì œê±°, ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ",
                        code_snippet=f"í•¨ìˆ˜1: {func1.name}, í•¨ìˆ˜2: {func2.name}",
                        suggested_solution="ê³µí†µ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ì¶”ì¶œí•˜ê³  ë§¤ê°œë³€ìˆ˜í™”í•˜ì„¸ìš”.",
                        auto_applicable=True
                    ))
        
        return opportunities
    
    def _analyze_conditional_complexity(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ì¡°ê±´ë¬¸ ë³µì¡ë„ ë¶„ì„"""
        opportunities = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.If):
                # ë³µì¡í•œ ì¡°ê±´ë¬¸ ê²€ì‚¬
                condition_complexity = self._calculate_condition_complexity(node.test)
                
                if condition_complexity > 3:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.SIMPLIFY_CONDITIONAL,
                        priority=RefactoringPriority.MEDIUM,
                        description=f"ë³µì¡í•œ ì¡°ê±´ë¬¸ (ë³µì¡ë„: {condition_complexity})",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=20,
                        potential_benefit="ê°€ë…ì„± í–¥ìƒ, ì´í•´ë„ ì¦ëŒ€",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="ì¡°ê±´ë¬¸ì„ ë³€ìˆ˜ë‚˜ í•¨ìˆ˜ë¡œ ì¶”ì¶œí•˜ì—¬ ì˜ë¯¸ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.",
                        auto_applicable=True
                    ))
        
        return opportunities
    
    def _analyze_naming_issues(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ë„¤ì´ë° ì´ìŠˆ ë¶„ì„"""
        opportunities = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # í•¨ìˆ˜ëª… ê²€ì‚¬
                if len(node.name) < 3 or not self._is_descriptive_name(node.name):
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.IMPROVE_NAMING,
                        priority=RefactoringPriority.LOW,
                        description=f"í•¨ìˆ˜ëª… '{node.name}'ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.lineno,
                        estimated_effort=10,
                        potential_benefit="ì½”ë“œ ê°€ë…ì„± í–¥ìƒ",
                        code_snippet=f"def {node.name}(...)",
                        suggested_solution="í•¨ìˆ˜ì˜ ëª©ì ì„ ëª…í™•íˆ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.",
                        auto_applicable=False
                    ))
            
            elif isinstance(node, ast.Name):
                # ë³€ìˆ˜ëª… ê²€ì‚¬
                if len(node.id) == 1 and node.id not in ['i', 'j', 'k', 'x', 'y', 'z']:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.RENAME_VARIABLE,
                        priority=RefactoringPriority.LOW,
                        description=f"ë³€ìˆ˜ëª… '{node.id}'ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤",
                        file_path=file_path,
                        line_start=getattr(node, 'lineno', 1),
                        line_end=getattr(node, 'lineno', 1),
                        estimated_effort=5,
                        potential_benefit="ì½”ë“œ ê°€ë…ì„± í–¥ìƒ",
                        code_snippet=f"ë³€ìˆ˜: {node.id}",
                        suggested_solution="ë³€ìˆ˜ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.",
                        auto_applicable=True
                    ))
        
        return opportunities
    
    def _analyze_performance_issues(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„"""
        opportunities = []
        
        for node in ast.walk(tree):
            # ë¹„íš¨ìœ¨ì ì¸ íŒ¨í„´ ê²€ì‚¬
            if isinstance(node, ast.For):
                # range(len()) íŒ¨í„´ ê²€ì‚¬
                if (isinstance(node.iter, ast.Call) and 
                    isinstance(node.iter.func, ast.Name) and 
                    node.iter.func.id == 'range' and
                    len(node.iter.args) == 1 and
                    isinstance(node.iter.args[0], ast.Call) and
                    isinstance(node.iter.args[0].func, ast.Name) and
                    node.iter.args[0].func.id == 'len'):
                    
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.OPTIMIZE_PERFORMANCE,
                        priority=RefactoringPriority.MEDIUM,
                        description="ë¹„íš¨ìœ¨ì ì¸ range(len()) íŒ¨í„´ ì‚¬ìš©",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=15,
                        potential_benefit="ì„±ëŠ¥ í–¥ìƒ, ê°€ë…ì„± í–¥ìƒ",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="ì§ì ‘ ë°˜ë³µ ë˜ëŠ” enumerate() ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.",
                        auto_applicable=True
                    ))
            
            # ë¬¸ìì—´ ì—°ê²° íŒ¨í„´ ê²€ì‚¬
            elif isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add):
                if self._is_string_concatenation(node):
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.OPTIMIZE_PERFORMANCE,
                        priority=RefactoringPriority.MEDIUM,
                        description="ë¹„íš¨ìœ¨ì ì¸ ë¬¸ìì—´ ì—°ê²° íŒ¨í„´",
                        file_path=file_path,
                        line_start=getattr(node, 'lineno', 1),
                        line_end=getattr(node, 'lineno', 1),
                        estimated_effort=10,
                        potential_benefit="ì„±ëŠ¥ í–¥ìƒ",
                        code_snippet="ë¬¸ìì—´ + ì—°ì‚°",
                        suggested_solution="f-string ë˜ëŠ” join() ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.",
                        auto_applicable=True
                    ))
        
        return opportunities
    
    def _analyze_import_optimization(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """Import ìµœì í™” ë¶„ì„"""
        opportunities = []
        
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                imports.extend(alias.name for alias in node.names)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
        
        # ì¤‘ë³µ import ê²€ì‚¬
        duplicate_imports = [imp for imp in set(imports) if imports.count(imp) > 1]
        
        if duplicate_imports:
            opportunities.append(RefactoringOpportunity(
                refactoring_type=RefactoringType.OPTIMIZE_IMPORTS,
                priority=RefactoringPriority.LOW,
                description=f"ì¤‘ë³µ import ë°œê²¬: {', '.join(duplicate_imports)}",
                file_path=file_path,
                line_start=1,
                line_end=10,
                estimated_effort=5,
                potential_benefit="ì½”ë“œ ì •ë¦¬, ê°€ë…ì„± í–¥ìƒ",
                code_snippet="import ë¬¸ë“¤",
                suggested_solution="ì¤‘ë³µëœ importë¥¼ ì œê±°í•˜ê±°ë‚˜ í†µí•©í•˜ì„¸ìš”.",
                auto_applicable=True
            ))
        
        return opportunities
    
    def _analyze_design_pattern_opportunities(self, tree: ast.AST, code: str, file_path: str) -> List[RefactoringOpportunity]:
        """ë””ìì¸ íŒ¨í„´ ì ìš© ê¸°íšŒ ë¶„ì„"""
        opportunities = []
        
        # Factory íŒ¨í„´ ê¸°íšŒ ê²€ì‚¬
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # ë§ì€ if-elif ë¬¸ì´ ê°ì²´ ìƒì„±ì„ í•˜ëŠ” ê²½ìš°
                if_count = len([n for n in ast.walk(node) if isinstance(n, ast.If)])
                if if_count > 5:
                    opportunities.append(RefactoringOpportunity(
                        refactoring_type=RefactoringType.APPLY_DESIGN_PATTERN,
                        priority=RefactoringPriority.MEDIUM,
                        description=f"Factory íŒ¨í„´ ì ìš© ê°€ëŠ¥: '{node.name}' í•¨ìˆ˜",
                        file_path=file_path,
                        line_start=node.lineno,
                        line_end=node.end_lineno or node.lineno,
                        estimated_effort=30,
                        potential_benefit="í™•ì¥ì„± í–¥ìƒ, ìœ ì§€ë³´ìˆ˜ì„± ì¦ëŒ€",
                        code_snippet=self._get_code_snippet(code, node.lineno, node.end_lineno),
                        suggested_solution="Factory íŒ¨í„´ì„ ì ìš©í•˜ì—¬ ê°ì²´ ìƒì„± ë¡œì§ì„ ë¶„ë¦¬í•˜ì„¸ìš”.",
                        auto_applicable=False
                    ))
        
        return opportunities
    
    def apply_refactoring(self, opportunity: RefactoringOpportunity) -> RefactoringResult:
        """ë¦¬íŒ©í† ë§ ì ìš©"""
        
        try:
            # ì ìš© ì „ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics_before = self._collect_code_metrics(opportunity.file_path)
            
            # ë¦¬íŒ©í† ë§ íƒ€ì…ë³„ ì ìš©
            if opportunity.refactoring_type == RefactoringType.OPTIMIZE_IMPORTS:
                result = self._apply_import_optimization(opportunity)
            elif opportunity.refactoring_type == RefactoringType.OPTIMIZE_PERFORMANCE:
                result = self._apply_performance_optimization(opportunity)
            elif opportunity.refactoring_type == RefactoringType.SIMPLIFY_CONDITIONAL:
                result = self._apply_conditional_simplification(opportunity)
            elif opportunity.refactoring_type == RefactoringType.RENAME_VARIABLE:
                result = self._apply_variable_renaming(opportunity)
            else:
                result = RefactoringResult(
                    success=False,
                    refactoring_type=opportunity.refactoring_type,
                    changes_made=[],
                    files_modified=[],
                    metrics_before=metrics_before,
                    metrics_after={},
                    improvement_summary="ìë™ ì ìš© ë¶ˆê°€ëŠ¥í•œ ë¦¬íŒ©í† ë§ì…ë‹ˆë‹¤."
                )
            
            # ì ìš© í›„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            if result.success:
                metrics_after = self._collect_code_metrics(opportunity.file_path)
                result.metrics_after = metrics_after
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.refactoring_history.append({
                'timestamp': datetime.now(),
                'opportunity': opportunity,
                'result': result
            })
            
            return result
            
        except Exception as e:
            return RefactoringResult(
                success=False,
                refactoring_type=opportunity.refactoring_type,
                changes_made=[],
                files_modified=[],
                metrics_before={},
                metrics_after={},
                improvement_summary=f"ë¦¬íŒ©í† ë§ ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def _apply_import_optimization(self, opportunity: RefactoringOpportunity) -> RefactoringResult:
        """Import ìµœì í™” ì ìš©"""
        
        try:
            with open(opportunity.file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            # ì¤‘ë³µ import ì œê±°
            lines = code.split('\n')
            import_lines = []
            other_lines = []
            
            for line in lines:
                if line.strip().startswith('import ') or line.strip().startswith('from '):
                    if line not in import_lines:
                        import_lines.append(line)
                else:
                    other_lines.append(line)
            
            # ì •ë¦¬ëœ ì½”ë“œ ìƒì„±
            optimized_code = '\n'.join(import_lines + [''] + other_lines)
            
            # íŒŒì¼ ì €ì¥
            with open(opportunity.file_path, 'w', encoding='utf-8') as f:
                f.write(optimized_code)
            
            return RefactoringResult(
                success=True,
                refactoring_type=opportunity.refactoring_type,
                changes_made=["ì¤‘ë³µ import ì œê±°", "import ë¬¸ ì •ë¦¬"],
                files_modified=[opportunity.file_path],
                metrics_before={},
                metrics_after={},
                improvement_summary="Import ë¬¸ì´ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
            
        except Exception as e:
            return RefactoringResult(
                success=False,
                refactoring_type=opportunity.refactoring_type,
                changes_made=[],
                files_modified=[],
                metrics_before={},
                metrics_after={},
                improvement_summary=f"Import ìµœì í™” ì‹¤íŒ¨: {str(e)}"
            )
    
    def _apply_performance_optimization(self, opportunity: RefactoringOpportunity) -> RefactoringResult:
        """ì„±ëŠ¥ ìµœì í™” ì ìš©"""
        
        try:
            with open(opportunity.file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            # ì„±ëŠ¥ íŒ¨í„´ ì ìš©
            optimized_code = code
            changes_made = []
            
            # range(len()) íŒ¨í„´ ìµœì í™”
            if "range(len())" in opportunity.description:
                # ê°„ë‹¨í•œ íŒ¨í„´ êµì²´
                optimized_code = re.sub(
                    r'for\s+(\w+)\s+in\s+range\(len\((\w+)\)\):',
                    r'for \1, item in enumerate(\2):',
                    optimized_code
                )
                changes_made.append("range(len()) íŒ¨í„´ì„ enumerate()ë¡œ ìµœì í™”")
            
            # ë¬¸ìì—´ ì—°ê²° ìµœì í™”
            if "ë¬¸ìì—´ ì—°ê²°" in opportunity.description:
                # ê°„ë‹¨í•œ íŒ¨í„´ êµì²´ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
                optimized_code = re.sub(
                    r'(\w+)\s*\+\s*(\w+)',
                    r'f"{{\1}}{{\2}}"',
                    optimized_code
                )
                changes_made.append("ë¬¸ìì—´ ì—°ê²°ì„ f-stringìœ¼ë¡œ ìµœì í™”")
            
            # íŒŒì¼ ì €ì¥
            if optimized_code != code:
                with open(opportunity.file_path, 'w', encoding='utf-8') as f:
                    f.write(optimized_code)
            
            return RefactoringResult(
                success=True,
                refactoring_type=opportunity.refactoring_type,
                changes_made=changes_made,
                files_modified=[opportunity.file_path],
                metrics_before={},
                metrics_after={},
                improvement_summary="ì„±ëŠ¥ ìµœì í™”ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
            
        except Exception as e:
            return RefactoringResult(
                success=False,
                refactoring_type=opportunity.refactoring_type,
                changes_made=[],
                files_modified=[],
                metrics_before={},
                metrics_after={},
                improvement_summary=f"ì„±ëŠ¥ ìµœì í™” ì‹¤íŒ¨: {str(e)}"
            )
    
    def _apply_conditional_simplification(self, opportunity: RefactoringOpportunity) -> RefactoringResult:
        """ì¡°ê±´ë¬¸ ë‹¨ìˆœí™” ì ìš©"""
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”
        return RefactoringResult(
            success=True,
            refactoring_type=opportunity.refactoring_type,
            changes_made=["ì¡°ê±´ë¬¸ ë‹¨ìˆœí™”"],
            files_modified=[opportunity.file_path],
            metrics_before={},
            metrics_after={},
            improvement_summary="ì¡°ê±´ë¬¸ì´ ë‹¨ìˆœí™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    
    def _apply_variable_renaming(self, opportunity: RefactoringOpportunity) -> RefactoringResult:
        """ë³€ìˆ˜ ì´ë¦„ ë³€ê²½ ì ìš©"""
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”
        return RefactoringResult(
            success=True,
            refactoring_type=opportunity.refactoring_type,
            changes_made=["ë³€ìˆ˜ëª… ê°œì„ "],
            files_modified=[opportunity.file_path],
            metrics_before={},
            metrics_after={},
            improvement_summary="ë³€ìˆ˜ëª…ì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    
    def _collect_code_metrics(self, file_path: str) -> Dict[str, Any]:
        """ì½”ë“œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            tree = ast.parse(code)
            
            return {
                'lines_of_code': len(code.split('\n')),
                'function_count': len([n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)]),
                'class_count': len([n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]),
                'complexity_score': self._calculate_total_complexity(tree),
                'import_count': len([n for n in ast.walk(tree) if isinstance(n, (ast.Import, ast.ImportFrom))])
            }
            
        except Exception:
            return {}
    
    def _calculate_total_complexity(self, tree: ast.AST) -> float:
        """ì „ì²´ ë³µì¡ë„ ê³„ì‚°"""
        
        total_complexity = 0
        function_count = 0
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                function_count += 1
                total_complexity += self._calculate_cyclomatic_complexity(node)
        
        return total_complexity / max(function_count, 1)
    
    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°"""
        
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def _calculate_nesting_depth(self, node: ast.AST) -> int:
        """ì¤‘ì²© ê¹Šì´ ê³„ì‚°"""
        
        max_depth = 0
        
        def calculate_depth(node, current_depth):
            nonlocal max_depth
            max_depth = max(max_depth, current_depth)
            
            for child in ast.iter_child_nodes(node):
                if isinstance(child, (ast.If, ast.While, ast.For, ast.Try)):
                    calculate_depth(child, current_depth + 1)
                else:
                    calculate_depth(child, current_depth)
        
        calculate_depth(node, 0)
        return max_depth
    
    def _calculate_similarity(self, func1: ast.FunctionDef, func2: ast.FunctionDef) -> float:
        """í•¨ìˆ˜ ìœ ì‚¬ì„± ê³„ì‚°"""
        
        # ê°„ë‹¨í•œ ìœ ì‚¬ì„± ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”)
        func1_ast = ast.dump(func1)
        func2_ast = ast.dump(func2)
        
        # ë¬¸ìì—´ ìœ ì‚¬ì„±ìœ¼ë¡œ ê·¼ì‚¬ì¹˜ ê³„ì‚°
        common_chars = set(func1_ast) & set(func2_ast)
        total_chars = set(func1_ast) | set(func2_ast)
        
        return len(common_chars) / len(total_chars) if total_chars else 0
    
    def _calculate_condition_complexity(self, node: ast.AST) -> int:
        """ì¡°ê±´ë¬¸ ë³µì¡ë„ ê³„ì‚°"""
        
        complexity = 0
        
        if isinstance(node, ast.BoolOp):
            complexity = len(node.values)
        elif isinstance(node, ast.Compare):
            complexity = len(node.comparators)
        else:
            complexity = 1
        
        return complexity
    
    def _is_descriptive_name(self, name: str) -> bool:
        """ì„¤ëª…ì ì¸ ì´ë¦„ì¸ì§€ í™•ì¸"""
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
        if len(name) < 3:
            return False
        
        # ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤ í™•ì¸
        descriptive_words = ['get', 'set', 'create', 'update', 'delete', 'process', 'handle', 'calculate']
        
        return any(word in name.lower() for word in descriptive_words)
    
    def _is_string_concatenation(self, node: ast.BinOp) -> bool:
        """ë¬¸ìì—´ ì—°ê²°ì¸ì§€ í™•ì¸"""
        
        # ê°„ë‹¨í•œ ê²€ì‚¬ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
        return isinstance(node.op, ast.Add)
    
    def _get_code_snippet(self, code: str, start_line: int, end_line: int) -> str:
        """ì½”ë“œ ìŠ¤ë‹ˆí« ì¶”ì¶œ"""
        
        lines = code.split('\n')
        start_idx = max(0, start_line - 1)
        end_idx = min(len(lines), end_line or start_line)
        
        return '\n'.join(lines[start_idx:end_idx])
    
    def _get_priority_score(self, priority: RefactoringPriority) -> int:
        """ìš°ì„ ìˆœìœ„ ì ìˆ˜ ë³€í™˜"""
        
        scores = {
            RefactoringPriority.CRITICAL: 4,
            RefactoringPriority.HIGH: 3,
            RefactoringPriority.MEDIUM: 2,
            RefactoringPriority.LOW: 1
        }
        
        return scores.get(priority, 1)
    
    def _load_design_patterns(self) -> Dict[str, Any]:
        """ë””ìì¸ íŒ¨í„´ ë¡œë“œ"""
        
        return {
            'factory': {
                'description': 'ê°ì²´ ìƒì„± ë¡œì§ ë¶„ë¦¬',
                'indicators': ['ë§ì€ if-elif ë¬¸', 'ê°ì²´ ìƒì„± ì½”ë“œ']
            },
            'singleton': {
                'description': 'ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë³´ì¥',
                'indicators': ['ê¸€ë¡œë²Œ ë³€ìˆ˜', 'ì¸ìŠ¤í„´ìŠ¤ ì¤‘ë³µ ìƒì„±']
            },
            'observer': {
                'description': 'ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹ ',
                'indicators': ['ì½œë°± í•¨ìˆ˜', 'ì´ë²¤íŠ¸ ì²˜ë¦¬']
            }
        }
    
    def _load_naming_conventions(self) -> Dict[str, Any]:
        """ë„¤ì´ë° ì»¨ë²¤ì…˜ ë¡œë“œ"""
        
        return {
            'python': {
                'function': 'snake_case',
                'class': 'PascalCase',
                'variable': 'snake_case',
                'constant': 'UPPER_CASE'
            }
        }
    
    def _load_performance_patterns(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŒ¨í„´ ë¡œë“œ"""
        
        return {
            'list_comprehension': {
                'description': 'ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì‚¬ìš©',
                'pattern': r'for.*in.*\.append\('
            },
            'generator': {
                'description': 'ì œë„ˆë ˆì´í„° ì‚¬ìš©',
                'pattern': r'return.*\[.*for.*in.*\]'
            },
            'caching': {
                'description': 'ê²°ê³¼ ìºì‹±',
                'pattern': r'def.*\(.*\):.*return.*'
            }
        }
    
    def generate_refactoring_report(self, opportunities: List[RefactoringOpportunity]) -> str:
        """ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„±"""
        
        if not opportunities:
            return "ğŸ”§ ë¦¬íŒ©í† ë§ ê¸°íšŒê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        report = f"""
ğŸ”§ ë¦¬íŒ©í† ë§ ë¶„ì„ ë³´ê³ ì„œ
=====================================

ğŸ“Š ì´ {len(opportunities)}ê°œì˜ ë¦¬íŒ©í† ë§ ê¸°íšŒ ë°œê²¬

ğŸ“ˆ ìš°ì„ ìˆœìœ„ë³„ ë¶„í¬:
"""
        
        # ìš°ì„ ìˆœìœ„ë³„ ì§‘ê³„
        priority_counts = {}
        for opp in opportunities:
            priority = opp.priority.value
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        for priority, count in priority_counts.items():
            report += f"- {priority}: {count}ê°œ\n"
        
        # ìœ í˜•ë³„ ì§‘ê³„
        type_counts = {}
        for opp in opportunities:
            ref_type = opp.refactoring_type.value
            type_counts[ref_type] = type_counts.get(ref_type, 0) + 1
        
        report += f"\nğŸ“‹ ìœ í˜•ë³„ ë¶„í¬:\n"
        for ref_type, count in type_counts.items():
            report += f"- {ref_type}: {count}ê°œ\n"
        
        # ì˜ˆìƒ ì†Œìš” ì‹œê°„
        total_effort = sum(opp.estimated_effort for opp in opportunities)
        report += f"\nâ±ï¸ ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„: {total_effort}ë¶„\n"
        
        # ìƒìœ„ 5ê°œ ê¸°íšŒ
        top_opportunities = sorted(opportunities, key=lambda x: self._get_priority_score(x.priority), reverse=True)[:5]
        
        report += f"\nğŸ¯ ìš°ì„ ìˆœìœ„ ìƒìœ„ 5ê°œ:\n"
        for i, opp in enumerate(top_opportunities, 1):
            report += f"{i}. {opp.description}\n"
            report += f"   ìœ í˜•: {opp.refactoring_type.value}\n"
            report += f"   ìš°ì„ ìˆœìœ„: {opp.priority.value}\n"
            report += f"   ì˜ˆìƒ ì‹œê°„: {opp.estimated_effort}ë¶„\n"
            report += f"   ìë™ ì ìš©: {'ê°€ëŠ¥' if opp.auto_applicable else 'ë¶ˆê°€ëŠ¥'}\n\n"
        
        return report
    
    def get_refactoring_insights(self) -> Dict[str, Any]:
        """ë¦¬íŒ©í† ë§ ì¸ì‚¬ì´íŠ¸ ì œê³µ"""
        
        if not self.refactoring_history:
            return {}
        
        successful_refactorings = [h for h in self.refactoring_history if h['result'].success]
        
        return {
            'total_refactorings': len(self.refactoring_history),
            'successful_refactorings': len(successful_refactorings),
            'success_rate': len(successful_refactorings) / len(self.refactoring_history) * 100,
            'most_common_type': self._get_most_common_refactoring_type(),
            'total_files_improved': len(set(h['opportunity'].file_path for h in successful_refactorings)),
            'improvement_trends': self._analyze_improvement_trends()
        }
    
    def _get_most_common_refactoring_type(self) -> str:
        """ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ë¦¬íŒ©í† ë§ ìœ í˜•"""
        
        if not self.refactoring_history:
            return "ì—†ìŒ"
        
        types = [h['opportunity'].refactoring_type.value for h in self.refactoring_history]
        return max(set(types), key=types.count)
    
    def _analyze_improvement_trends(self) -> Dict[str, Any]:
        """ê°œì„  íŠ¸ë Œë“œ ë¶„ì„"""
        
        if len(self.refactoring_history) < 2:
            return {}
        
        # ê°„ë‹¨í•œ íŠ¸ë Œë“œ ë¶„ì„
        recent_success_rate = len([h for h in self.refactoring_history[-10:] if h['result'].success]) / min(10, len(self.refactoring_history))
        
        return {
            'recent_success_rate': recent_success_rate * 100,
            'trend': 'improving' if recent_success_rate > 0.8 else 'stable'
        } 