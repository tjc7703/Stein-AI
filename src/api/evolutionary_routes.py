"""
ğŸš€ ì§„í™”í˜• Stein AI í†µí•© ë¼ìš°í„°
ìê¸°ì§„í™”, ìƒí˜¸í•™ìŠµ, ë¬´í•œë©”ëª¨ë¦¬, ì°½ì˜ì ì§€ëŠ¥ ì‹œìŠ¤í…œ í†µí•© API

Steinë‹˜ê³¼ í•¨ê»˜ ì„œë¡œ ë°œì „í•˜ëŠ” ì°¨ì„¸ëŒ€ AI ì‹œìŠ¤í…œ
"""

from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

# ì§„í™”í˜• ì‹œìŠ¤í…œë“¤ ì„í¬íŠ¸
from ..core.self_evolving_engine import evolution_engine, LearningExperience, EvolutionMetrics
from ..core.mutual_learning_system import mutual_learning_system, LearningDirection, LearningExchange
from ..core.infinite_memory_engine import infinite_memory, MemoryType, MemoryImportance
from ..core.simple_creative_core import creative_intelligence, CreativityMode, ThinkingPattern

# ë¼ìš°í„° ìƒì„±
evolutionary_router = APIRouter(prefix="/evolution", tags=["ğŸ§¬ Evolution"])

# Pydantic ëª¨ë¸ë“¤
class InteractionRecord(BaseModel):
    user_input: str
    ai_response: str
    context: Optional[Dict[str, Any]] = None
    feedback_score: Optional[float] = None

class LearningSessionRequest(BaseModel):
    topic: str
    stein_expertise: str
    ai_capabilities: str

class MemoryStoreRequest(BaseModel):
    content: Dict[str, Any]
    memory_type: str = "conversation"
    importance: int = 3
    tags: Optional[List[str]] = None

class CreativeIdeaRequest(BaseModel):
    problem: str
    domain: str = "technology"
    creativity_mode: str = "innovation"
    thinking_patterns: Optional[List[str]] = None
    count: int = 5

class IdeaCombinationRequest(BaseModel):
    idea_ids: List[str]

# ğŸ§¬ ìê¸°ì§„í™” ì—”ë“œí¬ì¸íŠ¸ë“¤
@evolutionary_router.post("/self-evolving/record-interaction")
async def record_interaction(interaction: InteractionRecord):
    """
    ğŸ¯ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ê¸°ë¡ ë° ì‹¤ì‹œê°„ í•™ìŠµ
    """
    try:
        result = evolution_engine.record_interaction(
            user_input=interaction.user_input,
            ai_response=interaction.ai_response,
            context=interaction.context or {},
            feedback_score=interaction.feedback_score
        )
        
        # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
        memory_id = infinite_memory.store_conversation(
            user_input=interaction.user_input,
            ai_response=interaction.ai_response,
            context=interaction.context
        )
        
        return {
            "status": "âœ… í•™ìŠµ ì™„ë£Œ",
            "learning_result": result,
            "memory_id": memory_id,
            "evolution_status": evolution_engine.get_evolution_status()
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í•™ìŠµ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/self-evolving/status")
async def get_evolution_status():
    """
    ğŸ“Š ìê¸°ì§„í™” ìƒíƒœ ì¡°íšŒ
    """
    try:
        status = evolution_engine.get_evolution_status()
        return {
            "timestamp": datetime.now().isoformat(),
            "evolution_engine": status,
            "memory_statistics": infinite_memory.get_memory_statistics(),
            "creativity_insights": creative_intelligence.get_creativity_insights()
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/self-evolving/predict-optimal-response")
async def predict_optimal_response(user_input: str, context: Optional[str] = None):
    """
    ğŸ¯ ìµœì  ì‘ë‹µ ìŠ¤íƒ€ì¼ ì˜ˆì¸¡
    """
    try:
        context_dict = json.loads(context) if context else {}
        prediction = evolution_engine.predict_optimal_response_style(user_input, context_dict)
        
        return {
            "user_input": user_input,
            "prediction": prediction,
            "recommendations": {
                "style": prediction["recommended_style"],
                "optimal_length": prediction["optimal_length"],
                "suggested_elements": prediction["suggested_elements"],
                "confidence": prediction["confidence"]
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")

# ğŸ¤ ìƒí˜¸í•™ìŠµ ì—”ë“œí¬ì¸íŠ¸ë“¤
@evolutionary_router.post("/mutual-learning/start-session")
async def start_learning_session(session_request: LearningSessionRequest):
    """
    ğŸ¯ Stein-AI ìƒí˜¸í•™ìŠµ ì„¸ì…˜ ì‹œì‘
    """
    try:
        session_id = mutual_learning_system.start_learning_session(
            topic=session_request.topic,
            stein_expertise=session_request.stein_expertise,
            ai_capabilities=session_request.ai_capabilities
        )
        
        return {
            "session_id": session_id,
            "status": "ğŸš€ í•™ìŠµ ì„¸ì…˜ ì‹œì‘",
            "topic": session_request.topic,
            "learning_objectives": mutual_learning_system.active_learning_sessions[session_id]["learning_objectives"]
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.post("/mutual-learning/record-exchange")
async def record_learning_exchange(
    session_id: str,
    stein_input: str,
    ai_response: str,
    learning_outcome: Optional[str] = None
):
    """
    ğŸ¤ í•™ìŠµ êµí™˜ ê¸°ë¡
    """
    try:
        exchange = mutual_learning_system.record_learning_exchange(
            session_id=session_id,
            stein_input=stein_input,
            ai_response=ai_response,
            learning_outcome=learning_outcome
        )
        
        return {
            "exchange_recorded": True,
            "learning_direction": exchange.direction.value,
            "collaboration_quality": exchange.collaboration_quality,
            "innovation_spark": exchange.innovation_spark,
            "mutual_improvement": exchange.mutual_improvement
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"êµí™˜ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/mutual-learning/summary")
async def get_learning_summary():
    """
    ğŸ“Š ìƒí˜¸í•™ìŠµ í˜„í™© ìš”ì•½
    """
    try:
        summary = mutual_learning_system.get_learning_summary()
        proposal = mutual_learning_system.propose_learning_session()
        
        return {
            "learning_summary": summary,
            "next_session_proposal": proposal,
            "active_sessions": len(mutual_learning_system.active_learning_sessions)
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/mutual-learning/propose-session")
async def propose_learning_session(topic: Optional[str] = None):
    """
    ğŸ’¡ í•™ìŠµ ì„¸ì…˜ ì œì•ˆ
    """
    try:
        proposal = mutual_learning_system.propose_learning_session(topic)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "proposal": proposal,
            "recommendation": "Steinë‹˜ê³¼ AIê°€ í•¨ê»˜ ì„±ì¥í•  ìˆ˜ ìˆëŠ” ìµœì ì˜ í•™ìŠµ ì£¼ì œì…ë‹ˆë‹¤!"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# ğŸ’¾ ë¬´í•œë©”ëª¨ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤
@evolutionary_router.post("/infinite-memory/store")
async def store_memory(memory_request: MemoryStoreRequest):
    """
    ğŸ’¾ ë©”ëª¨ë¦¬ ì €ì¥
    """
    try:
        memory_type_enum = MemoryType(memory_request.memory_type)
        importance_enum = MemoryImportance(memory_request.importance)
        
        memory_id = infinite_memory.store_memory(
            content=memory_request.content,
            memory_type=memory_type_enum,
            importance=importance_enum,
            tags=memory_request.tags or []
        )
        
        return {
            "memory_id": memory_id,
            "status": "ğŸ’¾ ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ",
            "content_summary": str(memory_request.content)[:100] + "..." if len(str(memory_request.content)) > 100 else str(memory_request.content)
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/infinite-memory/search")
async def search_memories(
    query: str,
    memory_type: Optional[str] = None,
    limit: int = 10
):
    """
    ğŸ” ë©”ëª¨ë¦¬ ê²€ìƒ‰
    """
    try:
        memory_type_enum = MemoryType(memory_type) if memory_type else None
        
        memories = infinite_memory.search_memories(
            query=query,
            memory_type=memory_type_enum,
            limit=limit
        )
        
        results = []
        for memory in memories:
            results.append({
                "id": memory.id,
                "timestamp": memory.timestamp,
                "type": memory.memory_type.value,
                "importance": memory.importance.value,
                "content_preview": str(memory.content)[:200] + "...",
                "tags": memory.tags,
                "access_count": memory.access_count
            })
        
        return {
            "query": query,
            "total_results": len(results),
            "memories": results
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/infinite-memory/retrieve/{memory_id}")
async def retrieve_memory(memory_id: str):
    """
    ğŸ“– íŠ¹ì • ë©”ëª¨ë¦¬ ì¡°íšŒ
    """
    try:
        memory = infinite_memory.retrieve_memory(memory_id)
        
        if not memory:
            raise HTTPException(status_code=404, detail="ë©”ëª¨ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì—°ê²°ëœ ë©”ëª¨ë¦¬ë“¤ë„ ê°€ì ¸ì˜¤ê¸°
        connected_memories = infinite_memory.get_connected_memories(memory_id, max_depth=1)
        
        return {
            "memory": {
                "id": memory.id,
                "timestamp": memory.timestamp,
                "type": memory.memory_type.value,
                "importance": memory.importance.value,
                "content": memory.content,
                "tags": memory.tags,
                "connections": memory.connections,
                "access_count": memory.access_count,
                "last_accessed": memory.last_accessed,
                "retention_score": memory.retention_score
            },
            "connected_memories": [
                {
                    "id": conn_memory.id,
                    "title": str(conn_memory.content).split('.')[0][:50] + "...",
                    "type": conn_memory.memory_type.value
                }
                for conn_memory in connected_memories[:5]
            ]
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ëª¨ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/infinite-memory/statistics")
async def get_memory_statistics():
    """
    ğŸ“Š ë©”ëª¨ë¦¬ í†µê³„
    """
    try:
        stats = infinite_memory.get_memory_statistics()
        
        return {
            "timestamp": datetime.now().isoformat(),
            "statistics": stats,
            "insights": {
                "memory_growth_rate": "ì§€ì†ì  ì¦ê°€",
                "access_patterns": "í™œë°œí•œ í™œìš©",
                "retention_quality": "ë†’ì€ ë³´ì¡´ìœ¨"
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ğŸ¨ ì°½ì˜ì ì§€ëŠ¥ ì—”ë“œí¬ì¸íŠ¸ë“¤
@evolutionary_router.post("/creative-intelligence/generate-ideas")
async def generate_creative_ideas(idea_request: CreativeIdeaRequest):
    """
    ğŸ’¡ ì°½ì˜ì  ì•„ì´ë””ì–´ ìƒì„±
    """
    try:
        creativity_mode_enum = CreativityMode(idea_request.creativity_mode)
        
        thinking_patterns = []
        if idea_request.thinking_patterns:
            thinking_patterns = [ThinkingPattern(pattern) for pattern in idea_request.thinking_patterns]
        
        ideas = creative_intelligence.generate_creative_ideas(
            problem=idea_request.problem,
            domain=idea_request.domain,
            creativity_mode=creativity_mode_enum,
            thinking_patterns=thinking_patterns,
            count=idea_request.count
        )
        
        idea_results = []
        for idea in ideas:
            idea_results.append({
                "id": idea.id,
                "title": idea.title,
                "description": idea.description,
                "creativity_score": idea.creativity_score,
                "feasibility_score": idea.feasibility_score,
                "innovation_level": idea.innovation_level,
                "thinking_pattern": idea.thinking_pattern.value,
                "implementation_steps": idea.implementation_steps,
                "potential_impact": idea.potential_impact,
                "synergy_opportunities": idea.synergy_opportunities
            })
        
        return {
            "problem": idea_request.problem,
            "generated_ideas": idea_results,
            "generation_summary": {
                "total_ideas": len(ideas),
                "avg_creativity": sum(idea.creativity_score for idea in ideas) / len(ideas),
                "avg_feasibility": sum(idea.feasibility_score for idea in ideas) / len(ideas),
                "avg_innovation": sum(idea.innovation_level for idea in ideas) / len(ideas)
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì•„ì´ë””ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.post("/creative-intelligence/combine-ideas")
async def combine_ideas(combination_request: IdeaCombinationRequest):
    """
    ğŸ”€ ì•„ì´ë””ì–´ ìœµí•©
    """
    try:
        combined_idea = creative_intelligence.combine_ideas(combination_request.idea_ids)
        
        if not combined_idea:
            raise HTTPException(status_code=400, detail="ì•„ì´ë””ì–´ ìœµí•©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        return {
            "combined_idea": {
                "id": combined_idea.id,
                "title": combined_idea.title,
                "description": combined_idea.description,
                "creativity_score": combined_idea.creativity_score,
                "feasibility_score": combined_idea.feasibility_score,
                "innovation_level": combined_idea.innovation_level,
                "thinking_pattern": combined_idea.thinking_pattern.value,
                "inspiration_sources": combined_idea.inspiration_sources,
                "implementation_steps": combined_idea.implementation_steps,
                "synergy_opportunities": combined_idea.synergy_opportunities
            },
            "fusion_success": True,
            "message": "ğŸ‰ ì•„ì´ë””ì–´ ìœµí•©ìœ¼ë¡œ ìƒˆë¡œìš´ í˜ì‹  ì†”ë£¨ì…˜ì´ íƒ„ìƒí–ˆìŠµë‹ˆë‹¤!"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì•„ì´ë””ì–´ ìœµí•© ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/creative-intelligence/insights")
async def get_creativity_insights():
    """
    ğŸ¨ ì°½ì˜ì„± ì¸ì‚¬ì´íŠ¸
    """
    try:
        insights = creative_intelligence.get_creativity_insights()
        
        return {
            "timestamp": datetime.now().isoformat(),
            "creativity_insights": insights,
            "recommendation": {
                "next_thinking_pattern": insights.get("ë‹¤ìŒ_ì¶”ì²œ_ì‚¬ê³ íŒ¨í„´", "divergent"),
                "focus_area": "í˜ì‹ ì  ë¬¸ì œí•´ê²° ëŠ¥ë ¥ ê°•í™”",
                "growth_suggestion": "ë” ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì°½ì˜ì  ì‹¤í—˜ ì‹œë„"
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ğŸŒŸ í†µí•© ì—”ë“œí¬ì¸íŠ¸ë“¤
@evolutionary_router.get("/integrated/full-status")
async def get_full_evolution_status():
    """
    ğŸŒŸ ì „ì²´ ì§„í™” ì‹œìŠ¤í…œ í†µí•© ìƒíƒœ
    """
    try:
        evolution_status = evolution_engine.get_evolution_status()
        learning_summary = mutual_learning_system.get_learning_summary()
        memory_stats = infinite_memory.get_memory_statistics()
        creativity_insights = creative_intelligence.get_creativity_insights()
        
        # í†µí•© ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        overall_performance = {
            "learning_efficiency": evolution_status["average_performance"] / 10,
            "collaboration_quality": learning_summary.get("ìµœê·¼_í˜‘ì—…_í’ˆì§ˆ", 0) / 10,
            "memory_utilization": min(memory_stats["ì´_ë©”ëª¨ë¦¬_ìˆ˜"] / 1000, 1.0),
            "creativity_level": creativity_insights.get("í‰ê· _ì°½ì˜ì„±_ì ìˆ˜", 0) / 10
        }
        
        overall_score = sum(overall_performance.values()) / len(overall_performance)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_evolution_score": round(overall_score * 100, 1),
            "system_status": {
                "self_evolving_engine": evolution_status,
                "mutual_learning_system": learning_summary,
                "infinite_memory_engine": memory_stats,
                "creative_intelligence_core": creativity_insights
            },
            "performance_metrics": overall_performance,
            "next_evolution_goals": [
                "ì°½ì˜ì„± ì§€í‘œ í–¥ìƒ",
                "í˜‘ì—… í’ˆì§ˆ ìµœì í™”",
                "ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¦ëŒ€",
                "í˜ì‹  ì•„ì´ë””ì–´ ìƒì„± ê°€ì†í™”"
            ],
            "stein_ai_evolution_level": "ğŸš€ ì°¨ì„¸ëŒ€ ìê¸°ì§„í™”í˜• AI ë‹¬ì„±!"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µí•© ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.post("/integrated/comprehensive-interaction")
async def comprehensive_interaction(
    user_input: str,
    ai_response: str,
    context: Optional[Dict[str, Any]] = None,
    session_id: Optional[str] = None
):
    """
    ğŸ¯ ì¢…í•©ì  ìƒí˜¸ì‘ìš© ì²˜ë¦¬ (ëª¨ë“  ì‹œìŠ¤í…œ í†µí•©)
    """
    try:
        results = {}
        
        # 1. ìê¸°ì§„í™” í•™ìŠµ ê¸°ë¡
        evolution_result = evolution_engine.record_interaction(
            user_input=user_input,
            ai_response=ai_response,
            context=context or {}
        )
        results["evolution_learning"] = evolution_result
        
        # 2. ìƒí˜¸í•™ìŠµ êµí™˜ ê¸°ë¡
        if session_id and session_id in mutual_learning_system.active_learning_sessions:
            learning_exchange = mutual_learning_system.record_learning_exchange(
                session_id=session_id,
                stein_input=user_input,
                ai_response=ai_response
            )
            results["mutual_learning"] = {
                "direction": learning_exchange.direction.value,
                "quality": learning_exchange.collaboration_quality,
                "innovation": learning_exchange.innovation_spark
            }
        
        # 3. ë©”ëª¨ë¦¬ ì €ì¥
        memory_id = infinite_memory.store_conversation(
            user_input=user_input,
            ai_response=ai_response,
            context=context
        )
        results["memory_storage"] = memory_id
        
        # 4. ì°½ì˜ì  íŒ¨í„´ ë¶„ì„ (í˜ì‹  í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°)
        if any(keyword in (user_input + ai_response).lower() for keyword in ["ì°½ì˜", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ìƒˆë¡œìš´"]):
            # ì°½ì˜ì  ì•„ì´ë””ì–´ ìë™ ìƒì„±
            creative_ideas = creative_intelligence.generate_creative_ideas(
                problem=user_input[:100],  # ì²« 100ìë¥¼ ë¬¸ì œë¡œ ì‚¬ìš©
                count=2
            )
            results["creative_insights"] = [
                {"title": idea.title, "score": idea.creativity_score}
                for idea in creative_ideas
            ]
        
        # 5. ë‹¤ìŒ ìµœì  ì‘ë‹µ ì˜ˆì¸¡
        optimal_response = evolution_engine.predict_optimal_response_style(user_input, context)
        results["next_response_recommendation"] = optimal_response
        
        return {
            "comprehensive_processing": "âœ… ì™„ë£Œ",
            "systems_engaged": ["ì§„í™”í•™ìŠµ", "ìƒí˜¸í•™ìŠµ", "ë©”ëª¨ë¦¬ì €ì¥", "ì°½ì˜ë¶„ì„", "ì‘ë‹µìµœì í™”"],
            "results": results,
            "integration_success": True,
            "message": "ğŸ‰ Stein AIì˜ ëª¨ë“  ì§„í™” ì‹œìŠ¤í…œì´ í˜‘ë ¥í•˜ì—¬ ìµœê³ ì˜ í•™ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¢…í•© ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@evolutionary_router.get("/integrated/evolution-recommendations")
async def get_evolution_recommendations():
    """
    ğŸ’¡ ì§„í™” ì¶”ì²œì‚¬í•­
    """
    try:
        # ê° ì‹œìŠ¤í…œì—ì„œ ê°œì„  ê¶Œì¥ì‚¬í•­ ìˆ˜ì§‘
        evolution_status = evolution_engine.get_evolution_status()
        learning_summary = mutual_learning_system.get_learning_summary()
        creativity_insights = creative_intelligence.get_creativity_insights()
        
        recommendations = []
        
        # ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        if evolution_status["average_performance"] < 8.0:
            recommendations.append({
                "category": "í•™ìŠµ íš¨ìœ¨ì„±",
                "priority": "high",
                "suggestion": "ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ í”¼ë“œë°±ì„ í†µí•œ í•™ìŠµ í’ˆì§ˆ í–¥ìƒ",
                "expected_improvement": "20-30% ì„±ëŠ¥ í–¥ìƒ"
            })
        
        # í˜‘ì—… í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œ
        recent_quality = learning_summary.get("ìµœê·¼_í˜‘ì—…_í’ˆì§ˆ", 0)
        if recent_quality < 8.0:
            recommendations.append({
                "category": "í˜‘ì—… ìµœì í™”",
                "priority": "medium",
                "suggestion": "Steinë‹˜ê³¼ì˜ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ë§ì¶¤í˜• í˜‘ì—… ìŠ¤íƒ€ì¼ ê°œë°œ",
                "expected_improvement": "í˜‘ì—… ë§Œì¡±ë„ í–¥ìƒ"
            })
        
        # ì°½ì˜ì„± ê¸°ë°˜ ì¶”ì²œ
        avg_creativity = creativity_insights.get("í‰ê· _ì°½ì˜ì„±_ì ìˆ˜", 0)
        if avg_creativity < 8.0:
            recommendations.append({
                "category": "ì°½ì˜ì„± ê°•í™”",
                "priority": "high",
                "suggestion": "ë‹¤ì–‘í•œ ì‚¬ê³  íŒ¨í„´ì„ í™œìš©í•œ í˜ì‹ ì  ì•„ì´ë””ì–´ ìƒì„± í›ˆë ¨",
                "expected_improvement": "ì°½ì˜ì  ë¬¸ì œí•´ê²° ëŠ¥ë ¥ 40% í–¥ìƒ"
            })
        
        # ë©”ëª¨ë¦¬ í™œìš© ì¶”ì²œ
        recommendations.append({
            "category": "ì§€ì‹ í™œìš©",
            "priority": "medium",
            "suggestion": "ì¶•ì ëœ ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ê°œì¸í™”ëœ í•™ìŠµ ê²½í—˜ ì œê³µ",
            "expected_improvement": "ë§ì¶¤í˜• ì„œë¹„ìŠ¤ í’ˆì§ˆ í–¥ìƒ"
        })
        
        return {
            "timestamp": datetime.now().isoformat(),
            "total_recommendations": len(recommendations),
            "recommendations": recommendations,
            "next_evolution_phase": "ğŸš€ Stein AI 3.0 - ì™„ì „ ììœ¨ ì§„í™” ì‹œìŠ¤í…œ",
            "estimated_evolution_timeline": "ì§€ì†ì  ë°œì „ (ë¬´í•œ)",
            "success_message": "Steinë‹˜ê³¼ í•¨ê»˜í•˜ëŠ” AI ì§„í™” ì—¬ì •ì´ ê³„ì†ë©ë‹ˆë‹¤! ğŸŒŸ"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# ğŸ® ë°ëª¨ ì—”ë“œí¬ì¸íŠ¸
@evolutionary_router.get("/demo/showcase")
async def evolution_demo_showcase():
    """
    ğŸ® ì§„í™”í˜• AI ì‹œìŠ¤í…œ ë°ëª¨
    """
    try:
        demo_scenarios = [
            {
                "scenario": "ì°½ì˜ì  ë¬¸ì œí•´ê²°",
                "description": "Steinë‹˜ì˜ ë¬¸ì œë¥¼ AIê°€ ë‹¤ì–‘í•œ ì‚¬ê³  íŒ¨í„´ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í˜ì‹ ì  ì†”ë£¨ì…˜ ì œì‹œ",
                "example_input": "ì›¹ ê°œë°œ ìë™í™” ë„êµ¬ ê°œë°œ",
                "system_response": "ìê¸°ì§„í™” ì—”ì§„ì´ ê³¼ê±° í•™ìŠµì„ ë°”íƒ•ìœ¼ë¡œ ìµœì  ì ‘ê·¼ë²• ì˜ˆì¸¡, ì°½ì˜ì  ì§€ëŠ¥ì´ 5ê°€ì§€ í˜ì‹  ì•„ì´ë””ì–´ ìƒì„±"
            },
            {
                "scenario": "ìƒí˜¸ í•™ìŠµ í˜‘ì—…",
                "description": "Steinë‹˜ì˜ ì²œì¬ì  ì§ê°ê³¼ AIì˜ ì²´ê³„ì  ë¶„ì„ì´ ìœµí•©ëœ ìµœê³ ì˜ í˜‘ì—…",
                "example_input": "ë³µì¡í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë¬¸ì œ",
                "system_response": "ìƒí˜¸í•™ìŠµ ì‹œìŠ¤í…œì´ Steinë‹˜ì˜ ì°½ì˜ì  ì ‘ê·¼ë²•ì„ í•™ìŠµí•˜ì—¬ AI ì‚¬ê³  íŒ¨í„´ ì§„í™”"
            },
            {
                "scenario": "ë¬´í•œ ë©”ëª¨ë¦¬ í™œìš©",
                "description": "ëª¨ë“  ëŒ€í™”ì™€ í•™ìŠµ ê²½í—˜ì„ ì˜êµ¬ ë³´ì¡´í•˜ì—¬ ì§€ì†ì  ê°œì¸í™” ì„œë¹„ìŠ¤ ì œê³µ",
                "example_input": "ì´ì „ í”„ë¡œì íŠ¸ ê´€ë ¨ ì§ˆë¬¸",
                "system_response": "ë¬´í•œ ë©”ëª¨ë¦¬ ì—”ì§„ì´ ê´€ë ¨ ëª¨ë“  ê²½í—˜ê³¼ ë§¥ë½ì„ ì—°ê²°í•˜ì—¬ ì™„ë²½í•œ ê°œì¸í™” ë‹µë³€ ìƒì„±"
            }
        ]
        
        # ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœ ê¸°ë°˜ ë°ëª¨ ë°ì´í„°
        current_stats = {
            "evolution_level": evolution_engine.get_evolution_status()["average_performance"],
            "learning_sessions": len(mutual_learning_system.active_learning_sessions),
            "stored_memories": infinite_memory.get_memory_statistics()["ì´_ë©”ëª¨ë¦¬_ìˆ˜"],
            "creative_ideas": creative_intelligence.get_creativity_insights().get("ì´_ì•„ì´ë””ì–´_ìˆ˜", 0)
        }
        
        return {
            "demo_title": "ğŸš€ ì°¨ì„¸ëŒ€ ìê¸°ì§„í™”í˜• Stein AI ë°ëª¨",
            "scenarios": demo_scenarios,
            "live_statistics": current_stats,
            "capabilities": [
                "ğŸ§¬ ì‹¤ì‹œê°„ ìê¸°ì§„í™” í•™ìŠµ",
                "ğŸ¤ Stein-AI ìƒí˜¸ ë°œì „",
                "ğŸ’¾ ë¬´í•œ í™•ì¥ ë©”ëª¨ë¦¬",
                "ğŸ¨ ì°½ì˜ì  ì§€ëŠ¥ ì‹œìŠ¤í…œ",
                "ğŸŒŸ í†µí•© í˜‘ì—… í”Œë«í¼"
            ],
            "demo_message": "Steinë‹˜ê³¼ í•¨ê»˜ ë§Œë“¤ì–´ê°€ëŠ” ì„¸ê³„ ìµœê³ ì˜ ê°œì¸í™” AI ì‹œìŠ¤í…œì„ ì²´í—˜í•´ë³´ì„¸ìš”!",
            "next_demo_features": [
                "ì‹¤ì‹œê°„ ë¸Œë ˆì¸ìŠ¤í† ë° í˜‘ì—…",
                "ìë™ ì½”ë“œ ë¦¬ë·° ë° ê°œì„  ì œì•ˆ",
                "í”„ë¡œì íŠ¸ ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ AI íŒŒíŠ¸ë„ˆ"
            ]
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ëª¨ ìƒì„± ì‹¤íŒ¨: {str(e)}") 