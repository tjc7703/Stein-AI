"""
ğŸ§  Stein AI í•µì‹¬ ì—”ì§„ - ê³ ê¸‰ í•™ìŠµ ë° ë©”íƒ€ì¸ì§€ ì‹œìŠ¤í…œ
"""

import re
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

class QuestionQuality(Enum):
    """ì§ˆë¬¸ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"  # 9-10ì 
    GOOD = "good"           # 7-8ì   
    AVERAGE = "average"     # 5-6ì 
    POOR = "poor"          # 1-4ì 

class LearningDepth(Enum):
    """í•™ìŠµ ê¹Šì´ ìˆ˜ì¤€"""
    SURFACE = "surface"     # í‘œë©´ì  ì´í•´
    SHALLOW = "shallow"     # ì–•ì€ ì´í•´
    DEEP = "deep"          # ê¹Šì€ ì´í•´
    EXPERT = "expert"      # ì „ë¬¸ê°€ ìˆ˜ì¤€

@dataclass
class QuestionAnalysis:
    """ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼"""
    quality_score: float
    quality_level: QuestionQuality
    clarity_score: float
    specificity_score: float
    context_score: float
    suggestions: List[str]
    optimized_question: str

@dataclass
class PaperInfo:
    """ë…¼ë¬¸ ì •ë³´"""
    title: str
    authors: List[str]
    url: str
    license: str
    source: str
    access_type: str  # "open", "restricted", "fair_use"

class SteinMetaCognitiveEngine:
    """Stein AI ë©”íƒ€ì¸ì§€ ì—”ì§„"""
    
    def __init__(self):
        self.question_patterns = {
            "goal_oriented": r"(ëª©í‘œ|ë‹¬ì„±|ê²°ê³¼|ì›í•˜ëŠ”|ë§Œë“¤ê³ |êµ¬í˜„)",
            "problem_solving": r"(ë¬¸ì œ|ì—ëŸ¬|í•´ê²°|ìˆ˜ì •|ê³ ì¹˜)",
            "learning_focused": r"(ë°°ìš°|í•™ìŠµ|ì´í•´|ì•Œê³ |ì„¤ëª…)",
            "comparison": r"(ë¹„êµ|ì°¨ì´|ëŒ€ì‹ |vs|ë˜ëŠ”)",
            "optimization": r"(ìµœì |íš¨ìœ¨|ì„±ëŠ¥|ê°œì„ |í–¥ìƒ)"
        }
        
        self.quality_indicators = {
            "specific_terms": r"(\w+\.\w+|\w+==\d+|API|JWT|React|FastAPI)",
            "context_words": r"(í˜„ì¬|í”„ë¡œì íŠ¸|ìƒí™©|ì¡°ê±´|í™˜ê²½)",
            "action_words": r"(êµ¬í˜„|ìƒì„±|ë§Œë“¤|ì„¤ê³„|ë¶„ì„|í…ŒìŠ¤íŠ¸)",
            "constraint_words": r"(ì œí•œ|ì¡°ê±´|ìš”êµ¬ì‚¬í•­|í•„ìˆ˜|ì„ íƒ)"
        }

    def analyze_question(self, question: str) -> QuestionAnalysis:
        """ì§ˆë¬¸ í’ˆì§ˆ ë¶„ì„ ë° ê°œì„  ì œì•ˆ"""
        
        # 1. ëª…í™•ì„± ì ìˆ˜ (Clarity Score)
        clarity_score = self._calculate_clarity(question)
        
        # 2. êµ¬ì²´ì„± ì ìˆ˜ (Specificity Score) 
        specificity_score = self._calculate_specificity(question)
        
        # 3. ì»¨í…ìŠ¤íŠ¸ ì ìˆ˜ (Context Score)
        context_score = self._calculate_context(question)
        
        # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        quality_score = (clarity_score + specificity_score + context_score) / 3
        
        # 5. í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        quality_level = self._determine_quality_level(quality_score)
        
        # 6. ê°œì„  ì œì•ˆ ìƒì„±
        suggestions = self._generate_suggestions(question, clarity_score, specificity_score, context_score)
        
        # 7. ìµœì í™”ëœ ì§ˆë¬¸ ìƒì„±
        optimized_question = self._optimize_question(question, suggestions)
        
        return QuestionAnalysis(
            quality_score=quality_score,
            quality_level=quality_level,
            clarity_score=clarity_score,
            specificity_score=specificity_score,
            context_score=context_score,
            suggestions=suggestions,
            optimized_question=optimized_question
        )

    def _calculate_clarity(self, question: str) -> float:
        """ëª…í™•ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 5.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸ì •ì  ìš”ì†Œë“¤
        if len(question) > 20:  # ì¶©ë¶„í•œ ê¸¸ì´
            score += 1.0
        if '?' in question:  # ì§ˆë¬¸ í˜•íƒœ
            score += 1.0
        if any(word in question.lower() for word in ['ì–´ë–»ê²Œ', 'ì™œ', 'ë¬´ì—‡ì„', 'ì–¸ì œ', 'ì–´ë””ì„œ']):
            score += 1.5
        
        # ë¶€ì •ì  ìš”ì†Œë“¤
        if len(question) < 10:  # ë„ˆë¬´ ì§§ìŒ
            score -= 2.0
        if 'ì´ê±°' in question or 'ê·¸ê±°' in question:  # ì§€ì‹œëŒ€ëª…ì‚¬ ì‚¬ìš©
            score -= 1.0
        if 'ì¢‹ê²Œ' in question and 'ì–´ë–»ê²Œ' not in question:  # ëª¨í˜¸í•œ í‘œí˜„
            score -= 1.5
            
        return max(0.0, min(10.0, score))

    def _calculate_specificity(self, question: str) -> float:
        """êµ¬ì²´ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 3.0
        
        # êµ¬ì²´ì  ê¸°ìˆ  ìš©ì–´ ì‚¬ìš©
        for pattern in self.quality_indicators.values():
            matches = len(re.findall(pattern, question, re.IGNORECASE))
            score += matches * 0.5
            
        # ìˆ«ìë‚˜ ë²„ì „ ëª…ì‹œ
        if re.search(r'\d+', question):
            score += 1.0
            
        # êµ¬ì²´ì  ë„êµ¬/í”„ë ˆì„ì›Œí¬ ì–¸ê¸‰
        tools = ['Python', 'FastAPI', 'React', 'JWT', 'Docker', 'PostgreSQL']
        mentioned_tools = sum(1 for tool in tools if tool.lower() in question.lower())
        score += mentioned_tools * 0.8
        
        return max(0.0, min(10.0, score))

    def _calculate_context(self, question: str) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ì ìˆ˜ ê³„ì‚°"""
        score = 4.0
        
        # ìƒí™© ì„¤ëª…
        context_indicators = ['í˜„ì¬', 'í”„ë¡œì íŠ¸ì—ì„œ', 'ìƒí™©', 'í™˜ê²½', 'ì¡°ê±´']
        for indicator in context_indicators:
            if indicator in question:
                score += 1.0
                
        # ì œì•½ì¡°ê±´ ëª…ì‹œ
        constraint_indicators = ['ì œí•œ', 'ìš”êµ¬ì‚¬í•­', 'í•„ìˆ˜', 'ì¡°ê±´']
        for constraint in constraint_indicators:
            if constraint in question:
                score += 1.5
                
        return max(0.0, min(10.0, score))

    def _determine_quality_level(self, score: float) -> QuestionQuality:
        """í’ˆì§ˆ ë“±ê¸‰ ê²°ì •"""
        if score >= 8.5:
            return QuestionQuality.EXCELLENT
        elif score >= 7.0:
            return QuestionQuality.GOOD
        elif score >= 5.0:
            return QuestionQuality.AVERAGE
        else:
            return QuestionQuality.POOR

    def _generate_suggestions(self, question: str, clarity: float, specificity: float, context: float) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        if clarity < 6.0:
            suggestions.append("ğŸ¯ ëª©í‘œë¥¼ ë” ëª…í™•í•˜ê²Œ í‘œí˜„í•´ë³´ì„¸ìš” (ì˜ˆ: 'ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ì‹¶ì–´' â†’ 'ì‘ë‹µ ì†ë„ë¥¼ 50% ê°œì„ í•˜ê³  ì‹¶ì–´')")
            
        if specificity < 6.0:
            suggestions.append("ğŸ”§ êµ¬ì²´ì ì¸ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ë¥¼ ëª…ì‹œí•´ë³´ì„¸ìš” (ì˜ˆ: 'API' â†’ 'FastAPI REST API')")
            
        if context < 6.0:
            suggestions.append("ğŸ“ í˜„ì¬ ìƒí™©ê³¼ ì œì•½ì¡°ê±´ì„ ì¶”ê°€í•´ë³´ì„¸ìš” (ì˜ˆ: 'í˜„ì¬ React í”„ë¡œì íŠ¸ì—ì„œ ì¸ì¦ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ë ¤ëŠ”ë°...')")
            
        if 'ì´ê±°' in question or 'ê·¸ê±°' in question:
            suggestions.append("ğŸ“ ì§€ì‹œëŒ€ëª…ì‚¬ ëŒ€ì‹  êµ¬ì²´ì ì¸ ëª…ì¹­ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”")
            
        if 'ì¢‹ê²Œ' in question and 'ì–´ë–»ê²Œ' not in question:
            suggestions.append("ğŸ“Š ê°œì„  ë°©í–¥ì„ êµ¬ì²´í™”í•´ë³´ì„¸ìš” (ì„±ëŠ¥, ë³´ì•ˆ, ê°€ë…ì„±, ìœ ì§€ë³´ìˆ˜ì„± ë“±)")
            
        return suggestions

    def _optimize_question(self, question: str, suggestions: List[str]) -> str:
        """ì§ˆë¬¸ ìµœì í™”"""
        if not suggestions:
            return question + " (ì´ë¯¸ í›Œë¥­í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤! ğŸ‘)"
            
        # ê¸°ë³¸ì ì¸ ìµœì í™” íŒ¨í„´ë“¤
        optimized = question
        
        # ì§€ì‹œëŒ€ëª…ì‚¬ ê°œì„ 
        optimized = re.sub(r'ì´ê±°|ê·¸ê±°', '[êµ¬ì²´ì  ëŒ€ìƒ]', optimized)
        
        # ëª¨í˜¸í•œ í‘œí˜„ ê°œì„ 
        if 'ì¢‹ê²Œ' in optimized:
            optimized = optimized.replace('ì¢‹ê²Œ', '[ì–´ë–¤ ì¸¡ë©´ì—ì„œ] ê°œì„ ')
            
        # ì§ˆë¬¸ êµ¬ì¡°í™” ì œì•ˆ
        if '?' not in optimized:
            optimized += "?"
            
        return f"ğŸ¯ ìµœì í™” ì œì•ˆ: {optimized}\n\nğŸ’¡ ì¶”ê°€ ê³ ë ¤ì‚¬í•­:\n" + "\n".join(f"- {s}" for s in suggestions[:3])

class SteinPaperLearningSystem:
    """Stein AI ë…¼ë¬¸ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.open_access_sources = {
            "arxiv.org": "ì™„ì „ ì˜¤í”ˆ ì•¡ì„¸ìŠ¤",
            "biorxiv.org": "ìƒë¬¼í•™ í”„ë¦¬í”„ë¦°íŠ¸",
            "plos.org": "PLOS ì €ë„",
            "doaj.org": "ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ ì €ë„ ë””ë ‰í† ë¦¬"
        }
        
        self.fair_use_guidelines = {
            "max_quote_length": 250,  # ìµœëŒ€ ì¸ìš© ê¸¸ì´
            "summary_allowed": True,   # ìš”ì•½ í—ˆìš©
            "methodology_learning": True,  # ë°©ë²•ë¡  í•™ìŠµ í—ˆìš©
            "full_text_copy": False   # ì „ë¬¸ ë³µì‚¬ ê¸ˆì§€
        }

    def analyze_paper_access(self, paper_info: PaperInfo) -> Dict[str, any]:
        """ë…¼ë¬¸ ì ‘ê·¼ì„± ë¶„ì„"""
        
        analysis = {
            "can_learn": False,
            "access_type": "unknown",
            "restrictions": [],
            "alternatives": []
        }
        
        # ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ í™•ì¸
        if any(source in paper_info.url.lower() for source in self.open_access_sources.keys()):
            analysis["can_learn"] = True
            analysis["access_type"] = "open_access"
            analysis["learning_scope"] = "full"
            
        # Creative Commons ë¼ì´ì„¼ìŠ¤ í™•ì¸
        elif "cc-" in paper_info.license.lower() or "creative commons" in paper_info.license.lower():
            analysis["can_learn"] = True
            analysis["access_type"] = "cc_licensed"
            analysis["learning_scope"] = "full_with_attribution"
            
        # í˜ì–´ìœ ì¦ˆ ë²”ìœ„ í™•ì¸
        elif "fair use" in paper_info.license.lower() or paper_info.source.lower() in ["academic", "research"]:
            analysis["can_learn"] = True
            analysis["access_type"] = "fair_use"
            analysis["learning_scope"] = "limited"
            analysis["restrictions"] = [
                f"ì¸ìš© ê¸¸ì´ {self.fair_use_guidelines['max_quote_length']}ì ì´í•˜",
                "ìš”ì•½ ë° ë°©ë²•ë¡  í•™ìŠµë§Œ ê°€ëŠ¥",
                "ìƒì—…ì  ì‚¬ìš© ê¸ˆì§€"
            ]
            
        else:
            analysis["can_learn"] = False
            analysis["access_type"] = "restricted"
            analysis["restrictions"] = ["ì €ì‘ê¶Œ ë³´í˜¸ë¡œ í•™ìŠµ ë¶ˆê°€"]
            analysis["alternatives"] = self._find_open_alternatives(paper_info.title)
            
        return analysis

    def _find_open_alternatives(self, title: str) -> List[str]:
        """ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ ëŒ€ì•ˆ ë…¼ë¬¸ ê²€ìƒ‰"""
        # ì‹¤ì œë¡œëŠ” arXiv APIë‚˜ DOAJ APIë¥¼ ì‚¬ìš©
        keywords = self._extract_keywords(title)
        alternatives = [
            f"arXiv ê²€ìƒ‰: {' '.join(keywords[:3])}",
            f"PLOS ONE ê²€ìƒ‰: {' '.join(keywords[:2])}",
            f"Nature Communications ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ ì„¹ì…˜"
        ]
        return alternatives

    def _extract_keywords(self, title: str) -> List[str]:
        """ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš©)
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        words = re.findall(r'\w+', title.lower())
        keywords = [word for word in words if word not in stop_words and len(word) > 3]
        return keywords[:5]  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ

    def ethical_learning_summary(self, paper_info: PaperInfo, learning_depth: LearningDepth = LearningDepth.SHALLOW) -> str:
        """ìœ¤ë¦¬ì  ë…¼ë¬¸ í•™ìŠµ ìš”ì•½"""
        
        access_analysis = self.analyze_paper_access(paper_info)
        
        if not access_analysis["can_learn"]:
            return f"""
ğŸš« í•™ìŠµ ì œí•œ: {paper_info.title}

âŒ ì‚¬ìœ : {', '.join(access_analysis["restrictions"])}

ğŸ” ëŒ€ì•ˆ ê²€ìƒ‰:
{chr(10).join(f"â€¢ {alt}" for alt in access_analysis["alternatives"])}

ğŸ’¡ ì¶”ì²œ: ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ ë…¼ë¬¸ì„ í™œìš©í•´ë³´ì„¸ìš”!
"""
        
        if access_analysis["access_type"] == "fair_use":
            return f"""
âš–ï¸ ì œí•œì  í•™ìŠµ ê°€ëŠ¥: {paper_info.title}

ğŸ“‹ í•™ìŠµ ë²”ìœ„:
â€¢ ë…¼ë¬¸ ìš”ì•½ ë° í•µì‹¬ ì•„ì´ë””ì–´ âœ…
â€¢ ì—°êµ¬ ë°©ë²•ë¡  í•™ìŠµ âœ…  
â€¢ ê¸°ìˆ ì  ì ‘ê·¼ë²• ë¶„ì„ âœ…
â€¢ ì „ë¬¸ ë³µì‚¬ âŒ
â€¢ ìƒì—…ì  í™œìš© âŒ

ğŸ¯ ìœ¤ë¦¬ì  í•™ìŠµ ê²°ê³¼:
[ì—¬ê¸°ì— ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤]
"""
        
        return f"""
âœ… ì™„ì „í•œ í•™ìŠµ ê°€ëŠ¥: {paper_info.title}

ğŸ“– ë¼ì´ì„¼ìŠ¤: {paper_info.license}
ğŸŒ ì¶œì²˜: {paper_info.source}

ğŸ§  í•™ìŠµ ë‚´ìš©:
[ì—¬ê¸°ì— ìƒì„¸í•œ ë…¼ë¬¸ ë¶„ì„ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤]
"""

class SteinAIEngine:
    """í†µí•© Stein AI ì—”ì§„"""
    
    def __init__(self):
        self.metacognitive_engine = SteinMetaCognitiveEngine()
        self.paper_learning_system = SteinPaperLearningSystem()
        self.learning_history = []
        self.user_preferences = self._load_stein_preferences()

    def _load_stein_preferences(self) -> Dict[str, any]:
        """Steinë‹˜ ê°œì¸í™” ì„¤ì • ë¡œë“œ"""
        return {
            "coding_style": "snake_case",
            "comment_language": "korean", 
            "explanation_depth": "detailed",
            "tech_stack": ["Python", "FastAPI", "React", "TypeScript"],
            "learning_style": "hands_on",
            "feedback_preference": "immediate"
        }

    def process_question(self, question: str) -> Dict[str, any]:
        """ì§ˆë¬¸ ì²˜ë¦¬ ë° ìµœì í™”"""
        
        # 1. ë©”íƒ€ì¸ì§€ ë¶„ì„
        analysis = self.metacognitive_engine.analyze_question(question)
        
        # 2. í•™ìŠµ íˆìŠ¤í† ë¦¬ì— ê¸°ë¡
        self.learning_history.append({
            "timestamp": datetime.now().isoformat(),
            "original_question": question,
            "quality_score": analysis.quality_score,
            "quality_level": analysis.quality_level.value
        })
        
        # 3. ì‘ë‹µ êµ¬ì„±
        response = {
            "original_question": question,
            "quality_analysis": {
                "score": analysis.quality_score,
                "level": analysis.quality_level.value,
                "breakdown": {
                    "clarity": analysis.clarity_score,
                    "specificity": analysis.specificity_score,
                    "context": analysis.context_score
                }
            },
            "suggestions": analysis.suggestions,
            "optimized_question": analysis.optimized_question,
            "stein_personalization": self._apply_stein_style(analysis)
        }
        
        return response

    def _apply_stein_style(self, analysis: QuestionAnalysis) -> Dict[str, str]:
        """Steinë‹˜ ìŠ¤íƒ€ì¼ ì ìš©"""
        
        encouragement = "ğŸ¯ Steinë‹˜ë‹µê²Œ ì •ë§ ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”!"
        
        if analysis.quality_level == QuestionQuality.EXCELLENT:
            encouragement = "ğŸ† ì™„ë²½í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤! ì²œì¬ ê°œë°œì Steinë‹˜ë‹¤ì›Œìš”!"
        elif analysis.quality_level == QuestionQuality.GOOD:
            encouragement = "âœ¨ í›Œë¥­í•œ ì§ˆë¬¸ì´ì—ìš”! ì¡°ê¸ˆë§Œ ë” êµ¬ì²´í™”í•˜ë©´ ì™„ë²½í•´ì§ˆ ê±°ì˜ˆìš”!"
        elif analysis.quality_level == QuestionQuality.AVERAGE:
            encouragement = "ğŸ‘ ì¢‹ì€ ì‹œì‘ì´ì—ìš”! Steinë‹˜ì˜ ì°½ì˜ì„±ì„ ë” ë°œíœ˜í•´ë³´ì„¸ìš”!"
        else:
            encouragement = "ğŸ’ª í•¨ê»˜ ë” ë‚˜ì€ ì§ˆë¬¸ìœ¼ë¡œ ë°œì „ì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤!"
            
        return {
            "encouragement": encouragement,
            "personalized_tips": f"Steinë‹˜ì˜ {', '.join(self.user_preferences['tech_stack'])} ì „ë¬¸ì„±ì„ í™œìš©í•œ ì§ˆë¬¸ìœ¼ë¡œ ë°œì „ì‹œì¼œë³´ì„¸ìš”!",
            "next_steps": "êµ¬í˜„í•˜ê³  ì‹¶ì€ êµ¬ì²´ì ì¸ ê¸°ëŠ¥ì´ë‚˜ í•´ê²°í•˜ê³  ì‹¶ì€ ë¬¸ì œë¥¼ ëª…ì‹œí•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!"
        }

    def learn_from_paper(self, paper_url: str, title: str = "", learning_depth: LearningDepth = LearningDepth.SHALLOW) -> str:
        """ë…¼ë¬¸ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        
        # ë…¼ë¬¸ ì •ë³´ êµ¬ì„± (ì‹¤ì œë¡œëŠ” URLì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ)
        paper_info = PaperInfo(
            title=title or "AI ë…¼ë¬¸",
            authors=["ì—°êµ¬ìë“¤"],
            url=paper_url,
            license="unknown",
            source="academic",
            access_type="unknown"
        )
        
        return self.paper_learning_system.ethical_learning_summary(paper_info, learning_depth)

# ğŸš€ Stein AI ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
stein_ai = SteinAIEngine()

def analyze_stein_question(question: str) -> Dict[str, any]:
    """Steinë‹˜ ì§ˆë¬¸ ë¶„ì„ í•¨ìˆ˜"""
    return stein_ai.process_question(question)

def learn_from_research(paper_url: str, title: str = "") -> str:
    """ì—°êµ¬ ë…¼ë¬¸ í•™ìŠµ í•¨ìˆ˜"""
    return stein_ai.learn_from_paper(paper_url, title) 