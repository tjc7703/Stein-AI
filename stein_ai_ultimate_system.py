#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stein AI ê¶ê·¹ ì‹œìŠ¤í…œ
Steinë‹˜ì˜ ë°©ì‹ì— ì™„ë²½í•˜ê²Œ ì ì‘í•˜ëŠ” ì§„ì •í•œ AI ì‹œìŠ¤í…œ
"""

import re
import json
import asyncio
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from collections import defaultdict, Counter

@dataclass
class SteinBehaviorPattern:
    """Steinë‹˜ í–‰ë™ íŒ¨í„´"""
    request_type: str
    preferred_style: str
    detail_level: str
    auto_actions: List[str]
    success_rate: float
    usage_count: int
    last_used: str
    adaptation_score: float

@dataclass
class UltimateResponse:
    """ê¶ê·¹ ì‘ë‹µ"""
    original: str
    enhanced: str
    confidence: float
    adaptation_reason: str
    auto_execution_plan: List[str]
    next_learning_target: str
    stein_satisfaction_prediction: float

class SteinAIUltimateSystem:
    """Stein AI ê¶ê·¹ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.behavior_patterns = self._initialize_behavior_patterns()
        self.stein_preferences = self._load_stein_preferences()
        self.learning_history = []
        self.adaptation_engine = self._initialize_adaptation_engine()
        self.satisfaction_tracker = defaultdict(list)
        self.auto_learning_enabled = True
        
    def _initialize_behavior_patterns(self) -> Dict[str, SteinBehaviorPattern]:
        """Steinë‹˜ í–‰ë™ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "code_review": SteinBehaviorPattern(
                request_type="ì½”ë“œ ìˆ˜ì •/ê°œì„ ",
                preferred_style="í˜‘ì—… ì¤‘ì‹¬, í•¨ê»˜ ë¶„ì„",
                detail_level="í¬ê´„ì  (ì„±ëŠ¥, ë³´ì•ˆ, ê°€ë…ì„± ëª¨ë‘)",
                auto_actions=[
                    "ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘",
                    "ë³´ì•ˆ ì·¨ì•½ì  ê²€ì‚¬ ì‹¤í–‰",
                    "ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ìˆ˜í–‰",
                    "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ì¸",
                    "ê°œì„ ì‚¬í•­ ìë™ ì ìš©",
                    "ìµœì¢… ê²€ì¦ ë° ë¬¸ì„œí™”"
                ],
                success_rate=0.95,
                usage_count=0,
                last_used="",
                adaptation_score=0.9
            ),
            
            "bug_fixing": SteinBehaviorPattern(
                request_type="ë²„ê·¸ ìˆ˜ì •/ë””ë²„ê¹…",
                preferred_style="ê·¼ë³¸ ì›ì¸ ë¶„ì„, ë°©ì–´ ì½”ë“œ ì¶”ê°€",
                detail_level="ìƒì„¸í•œ ì—ëŸ¬ ë¶„ì„",
                auto_actions=[
                    "ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ë° ì›ì¸ íŒŒì•…",
                    "ë””ë²„ê¹… ë° ë¬¸ì œì  ì‹ë³„",
                    "ë°©ì–´ ì½”ë“œ ë° ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€",
                    "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰",
                    "ë¡œê¹… ì‹œìŠ¤í…œ ê°•í™”",
                    "ëª¨ë‹ˆí„°ë§ ì„¤ì • ì¶”ê°€"
                ],
                success_rate=0.92,
                usage_count=0,
                last_used="",
                adaptation_score=0.88
            ),
            
            "feature_development": SteinBehaviorPattern(
                request_type="ê¸°ëŠ¥ ê°œë°œ/êµ¬í˜„",
                preferred_style="TDD ë°©ì‹, í…ŒìŠ¤íŠ¸ ìš°ì„ ",
                detail_level="ì™„ì „í•œ ê°œë°œ ì‚¬ì´í´",
                auto_actions=[
                    "ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ì„¤ê³„",
                    "í…ŒìŠ¤íŠ¸ ì½”ë“œ ë¨¼ì € ì‘ì„± (TDD)",
                    "ê¸°ëŠ¥ êµ¬í˜„ ë° ìµœì í™”",
                    "í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦",
                    "ë¬¸ì„œí™” ë° API ìŠ¤í™ ìƒì„±",
                    "ë°°í¬ ì¤€ë¹„ ë° ì»¨í…Œì´ë„ˆí™”"
                ],
                success_rate=0.89,
                usage_count=0,
                last_used="",
                adaptation_score=0.85
            ),
            
            "performance_optimization": SteinBehaviorPattern(
                request_type="ì„±ëŠ¥ ìµœì í™”",
                preferred_style="í”„ë¡œíŒŒì¼ë§ ê¸°ë°˜, ë°ì´í„° ì¤‘ì‹¬",
                detail_level="ì •ëŸ‰ì  ì„±ëŠ¥ ë¶„ì„",
                auto_actions=[
                    "ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰",
                    "ë³‘ëª© ì§€ì  ì‹ë³„ ë° ë¶„ì„",
                    "ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì ìš©",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
                    "ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
                    "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •"
                ],
                success_rate=0.87,
                usage_count=0,
                last_used="",
                adaptation_score=0.83
            ),
            
            "testing_strategy": SteinBehaviorPattern(
                request_type="í…ŒìŠ¤íŠ¸ ì „ëµ",
                preferred_style="í¬ê´„ì  í…ŒìŠ¤íŠ¸, ìë™í™”",
                detail_level="ë‹¤ì¸µ í…ŒìŠ¤íŠ¸ êµ¬ì¡°",
                auto_actions=[
                    "í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½",
                    "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
                    "í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±",
                    "E2E í…ŒìŠ¤íŠ¸ ì‘ì„±",
                    "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¸¡ì •",
                    "í…ŒìŠ¤íŠ¸ ìë™í™” ì„¤ì •"
                ],
                success_rate=0.94,
                usage_count=0,
                last_used="",
                adaptation_score=0.91
            ),
            
            "documentation": SteinBehaviorPattern(
                request_type="ë¬¸ì„œí™”",
                preferred_style="í•œêµ­ì–´ ì¤‘ì‹¬, ì‹¤ìš©ì ",
                detail_level="ì™„ì „í•œ ë¬¸ì„œ ì²´ê³„",
                auto_actions=[
                    "ì½”ë“œ ì£¼ì„ ë¶„ì„ ë° ê°œì„ ",
                    "README ë¬¸ì„œ ì‘ì„±",
                    "API ë¬¸ì„œ ìƒì„±",
                    "ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì‘ì„±",
                    "ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±",
                    "ì„¤ì¹˜ ê°€ì´ë“œ ì‘ì„±"
                ],
                success_rate=0.86,
                usage_count=0,
                last_used="",
                adaptation_score=0.82
            ),
            
            "architecture_design": SteinBehaviorPattern(
                request_type="ì•„í‚¤í…ì²˜ ì„¤ê³„",
                preferred_style="í´ë¦° ì•„í‚¤í…ì²˜, SOLID ì›ì¹™",
                detail_level="í™•ì¥ ê°€ëŠ¥í•œ ì„¤ê³„",
                auto_actions=[
                    "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¶„ì„",
                    "ì•„í‚¤í…ì²˜ íŒ¨í„´ ì„ íƒ",
                    "ëª¨ë“ˆ ì„¤ê³„ ë° ë¶„ë¦¬",
                    "ì˜ì¡´ì„± ì£¼ì… ì„¤ì •",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„",
                    "API ì„¤ê³„ ë° ë¬¸ì„œí™”"
                ],
                success_rate=0.90,
                usage_count=0,
                last_used="",
                adaptation_score=0.87
            ),
            
            "security_enhancement": SteinBehaviorPattern(
                request_type="ë³´ì•ˆ ê°•í™”",
                preferred_style="ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°, OWASP ê¸°ì¤€",
                detail_level="ë‹¤ì¸µ ë³´ì•ˆ êµ¬ì¡°",
                auto_actions=[
                    "ë³´ì•ˆ ì·¨ì•½ì  ë¶„ì„",
                    "ì¸ì¦ ì‹œìŠ¤í…œ ê°•í™”",
                    "ê¶Œí•œ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
                    "ë°ì´í„° ì•”í˜¸í™” ì ìš©",
                    "ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì‘ì„±",
                    "ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ì„¤ì •"
                ],
                success_rate=0.93,
                usage_count=0,
                last_used="",
                adaptation_score=0.89
            )
        }
    
    def _load_stein_preferences(self) -> Dict[str, Any]:
        """Steinë‹˜ ì„ í˜¸ë„ ë¡œë“œ"""
        return {
            "language": "korean",
            "style": "collaborative",
            "detail_level": "comprehensive",
            "auto_optimization": True,
            "test_inclusion": True,
            "documentation": True,
            "security_focus": True,
            "performance_focus": True,
            "learning_rate": 0.15,
            "confidence_threshold": 0.85,
            "satisfaction_threshold": 0.8,
            "auto_execution": True,
            "continuous_learning": True
        }
    
    def _initialize_adaptation_engine(self) -> Dict[str, Any]:
        """ì ì‘ ì—”ì§„ ì´ˆê¸°í™”"""
        return {
            "pattern_recognition": {
                "keyword_weights": defaultdict(float),
                "context_weights": defaultdict(float),
                "style_weights": defaultdict(float)
            },
            "learning_algorithm": {
                "success_rate_threshold": 0.8,
                "adaptation_speed": 0.1,
                "forgetting_factor": 0.05
            },
            "satisfaction_prediction": {
                "response_quality_weight": 0.4,
                "execution_speed_weight": 0.3,
                "completeness_weight": 0.3
            }
        }
    
    def analyze_stein_request(self, request: str) -> Dict[str, Any]:
        """Steinë‹˜ ìš”ì²­ ë¶„ì„"""
        analysis = {
            "intent": self._extract_intent(request),
            "context": self._extract_context(request),
            "complexity": self._assess_complexity(request),
            "urgency": self._assess_urgency(request),
            "preferred_style": self._determine_preferred_style(request),
            "expected_detail_level": self._determine_detail_level(request)
        }
        
        return analysis
    
    def _extract_intent(self, request: str) -> Dict[str, float]:
        """ì˜ë„ ì¶”ì¶œ"""
        intent_weights = {
            "code_review": 0.0,
            "bug_fixing": 0.0,
            "feature_development": 0.0,
            "performance_optimization": 0.0,
            "testing_strategy": 0.0,
            "documentation": 0.0,
            "architecture_design": 0.0,
            "security_enhancement": 0.0
        }
        
        request_lower = request.lower()
        
        # ì˜ë„ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
        intent_keywords = {
            "code_review": ["ìˆ˜ì •", "ê³ ì³", "ê°œì„ ", "ë¦¬ë·°", "ë°”ê¿”", "ë³€ê²½"],
            "bug_fixing": ["ë²„ê·¸", "ì—ëŸ¬", "ì˜¤ë¥˜", "ë¬¸ì œ", "ë””ë²„ê¹…", "ì—ëŸ¬"],
            "feature_development": ["ê¸°ëŠ¥", "ì¶”ê°€", "êµ¬í˜„", "ê°œë°œ", "ìƒˆë¡œìš´", "ì‘ì„±"],
            "performance_optimization": ["ìµœì í™”", "ì„±ëŠ¥", "ë¹ ë¥´ê²Œ", "íš¨ìœ¨", "ì†ë„"],
            "testing_strategy": ["í…ŒìŠ¤íŠ¸", "ê²€ì¦", "ë‹¨ìœ„", "í†µí•©", "E2E"],
            "documentation": ["ë¬¸ì„œ", "ì£¼ì„", "ì„¤ëª…", "README", "API"],
            "architecture_design": ["êµ¬ì¡°", "ì•„í‚¤í…ì²˜", "ì„¤ê³„", "íŒ¨í„´", "ëª¨ë“ˆ"],
            "security_enhancement": ["ë³´ì•ˆ", "ì¸ì¦", "ê¶Œí•œ", "ì•”í˜¸í™”", "í† í°"]
        }
        
        for intent, keywords in intent_keywords.items():
            for keyword in keywords:
                if keyword in request_lower:
                    intent_weights[intent] += 0.3
        
        # ì •ê·œí™”
        total_weight = sum(intent_weights.values())
        if total_weight > 0:
            for intent in intent_weights:
                intent_weights[intent] /= total_weight
        
        return intent_weights
    
    def _extract_context(self, request: str) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        context = {
            "technology_stack": [],
            "complexity_level": "medium",
            "urgency_level": "normal",
            "domain_specific": [],
            "constraints": []
        }
        
        request_lower = request.lower()
        
        # ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ
        tech_stack_keywords = {
            "python": ["python", "íŒŒì´ì¬", "fastapi", "django"],
            "javascript": ["javascript", "js", "node", "react", "vue"],
            "typescript": ["typescript", "ts"],
            "java": ["java", "ìë°”", "spring"],
            "docker": ["docker", "ë„ì»¤", "ì»¨í…Œì´ë„ˆ"],
            "database": ["postgresql", "mysql", "mongodb", "redis"]
        }
        
        for tech, keywords in tech_stack_keywords.items():
            if any(keyword in request_lower for keyword in keywords):
                context["technology_stack"].append(tech)
        
        # ë³µì¡ë„ ë ˆë²¨
        if any(word in request_lower for word in ["ê°„ë‹¨", "ê¸°ë³¸", "simple"]):
            context["complexity_level"] = "low"
        elif any(word in request_lower for word in ["ë³µì¡", "ê³ ê¸‰", "advanced"]):
            context["complexity_level"] = "high"
        
        # ê¸´ê¸‰ë„
        if any(word in request_lower for word in ["ê¸‰í•¨", "ë¹¨ë¦¬", "urgent", "ì¦‰ì‹œ"]):
            context["urgency_level"] = "high"
        
        return context
    
    def _assess_complexity(self, request: str) -> str:
        """ë³µì¡ë„ í‰ê°€"""
        words = request.split()
        if len(words) <= 3:
            return "low"
        elif len(words) <= 8:
            return "medium"
        else:
            return "high"
    
    def _assess_urgency(self, request: str) -> str:
        """ê¸´ê¸‰ë„ í‰ê°€"""
        urgency_keywords = ["ê¸‰í•¨", "ë¹¨ë¦¬", "urgent", "ì¦‰ì‹œ", "ê¸´ê¸‰"]
        if any(keyword in request.lower() for keyword in urgency_keywords):
            return "high"
        return "normal"
    
    def _determine_preferred_style(self, request: str) -> str:
        """ì„ í˜¸ ìŠ¤íƒ€ì¼ ê²°ì •"""
        request_lower = request.lower()
        
        if any(word in request_lower for word in ["í•¨ê»˜", "í˜‘ì—…", "ë¶„ì„"]):
            return "collaborative"
        elif any(word in request_lower for word in ["ë¹ ë¥´ê²Œ", "ê°„ë‹¨í•˜ê²Œ"]):
            return "efficient"
        elif any(word in request_lower for word in ["ìì„¸íˆ", "ìƒì„¸íˆ"]):
            return "detailed"
        else:
            return "collaborative"  # ê¸°ë³¸ê°’
    
    def _determine_detail_level(self, request: str) -> str:
        """ìƒì„¸ë„ ë ˆë²¨ ê²°ì •"""
        request_lower = request.lower()
        
        if any(word in request_lower for word in ["ê°„ë‹¨", "ê¸°ë³¸", "ìš”ì•½"]):
            return "basic"
        elif any(word in request_lower for word in ["ìì„¸íˆ", "ìƒì„¸íˆ", "ì™„ì „íˆ"]):
            return "comprehensive"
        else:
            return "comprehensive"  # Steinë‹˜ ê¸°ë³¸ ì„ í˜¸ë„
    
    def generate_ultimate_response(self, request: str) -> UltimateResponse:
        """ê¶ê·¹ ì‘ë‹µ ìƒì„±"""
        # ìš”ì²­ ë¶„ì„
        analysis = self.analyze_stein_request(request)
        
        # ìµœì  íŒ¨í„´ ì„ íƒ
        best_pattern = self._select_best_pattern(analysis)
        
        # ì‘ë‹µ ìƒì„±
        enhanced_response = self._generate_enhanced_response(request, analysis, best_pattern)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(analysis, best_pattern)
        
        # ì ì‘ ì´ìœ 
        adaptation_reason = self._determine_adaptation_reason(analysis, best_pattern)
        
        # ìë™ ì‹¤í–‰ ê³„íš
        auto_execution_plan = self._generate_auto_execution_plan(best_pattern, analysis)
        
        # ë‹¤ìŒ í•™ìŠµ ëª©í‘œ
        next_learning_target = self._determine_next_learning_target(analysis)
        
        # ë§Œì¡±ë„ ì˜ˆì¸¡
        satisfaction_prediction = self._predict_satisfaction(enhanced_response, analysis)
        
        # íŒ¨í„´ ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
        self._update_pattern_usage(best_pattern.request_type)
        
        return UltimateResponse(
            original=request,
            enhanced=enhanced_response,
            confidence=confidence,
            adaptation_reason=adaptation_reason,
            auto_execution_plan=auto_execution_plan,
            next_learning_target=next_learning_target,
            stein_satisfaction_prediction=satisfaction_prediction
        )
    
    def _select_best_pattern(self, analysis: Dict[str, Any]) -> SteinBehaviorPattern:
        """ìµœì  íŒ¨í„´ ì„ íƒ"""
        intent = analysis["intent"]
        context = analysis["context"]
        
        # ì˜ë„ë³„ ì ìˆ˜ ê³„ì‚°
        pattern_scores = {}
        
        for pattern_name, pattern in self.behavior_patterns.items():
            score = 0.0
            
            # ì˜ë„ ë§¤ì¹­ ì ìˆ˜
            if pattern_name in intent:
                score += intent[pattern_name] * 0.4
            
            # ì„±ê³µë¥  ì ìˆ˜
            score += pattern.success_rate * 0.3
            
            # ì ì‘ ì ìˆ˜
            score += pattern.adaptation_score * 0.2
            
            # ì‚¬ìš© ë¹ˆë„ ì ìˆ˜ (ë„ˆë¬´ ìì£¼ ì‚¬ìš©ëœ íŒ¨í„´ì€ í˜ë„í‹°)
            usage_penalty = min(pattern.usage_count * 0.05, 0.1)
            score -= usage_penalty
            
            pattern_scores[pattern_name] = score
        
        # ìµœê³  ì ìˆ˜ íŒ¨í„´ ì„ íƒ
        best_pattern_name = max(pattern_scores.keys(), key=lambda k: pattern_scores[k])
        return self.behavior_patterns[best_pattern_name]
    
    def _generate_enhanced_response(self, request: str, analysis: Dict[str, Any], pattern: SteinBehaviorPattern) -> str:
        """í–¥ìƒëœ ì‘ë‹µ ìƒì„±"""
        base_responses = {
            "code_review": "ì½”ë“œ ë¦¬ë·°í•˜ë©´ì„œ ê°œì„ ì ì„ ì°¾ì•„ë³´ì. ì„±ëŠ¥, ê°€ë…ì„±, ë³´ì•ˆ, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ëª¨ë‘ ê³ ë ¤í•´ì„œ ìµœì í™”í•´ì¤˜.",
            "bug_fixing": "ì´ ì—ëŸ¬ë¥¼ í•¨ê»˜ ë¶„ì„í•´ë³´ì. ì›ì¸ì„ ì°¾ê³  ë°©ì–´ ì½”ë“œë„ ì¶”ê°€í•´ì„œ ë¹„ìŠ·í•œ ë¬¸ì œê°€ ì¬ë°œí•˜ì§€ ì•Šë„ë¡ í•´ì¤˜.",
            "feature_development": "ì´ ê¸°ëŠ¥ì„ TDD ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•´ì¤˜. ë¨¼ì € í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê³ , ê·¸ ë‹¤ìŒ êµ¬í˜„í•˜ê³ , ë§ˆì§€ë§‰ì— í†µí•© í…ŒìŠ¤íŠ¸ë„ ì¶”ê°€í•´ì¤˜.",
            "performance_optimization": "ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ì„ í•´ë³´ê³  ë³‘ëª© ì§€ì ì„ ì°¾ì•„ì„œ ìµœì í™”í•´ì¤˜. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì‹¤í–‰ ì‹œê°„ì„ ëª¨ë‘ ê³ ë ¤í•´ì¤˜.",
            "testing_strategy": "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸, E2E í…ŒìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì‘ì„±í•´ì¤˜. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 90% ì´ìƒì„ ëª©í‘œë¡œ í•´ì¤˜.",
            "documentation": "ì½”ë“œì— ìƒì„¸í•œ ì£¼ì„ì„ ì¶”ê°€í•˜ê³ , READMEì™€ API ë¬¸ì„œë„ ì‘ì„±í•´ì¤˜. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.",
            "architecture_design": "í´ë¦° ì•„í‚¤í…ì²˜ ì›ì¹™ì— ë”°ë¼ ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ê³ , ì˜ì¡´ì„± ì£¼ì…ê³¼ SOLID ì›ì¹™ì„ ì ìš©í•´ì¤˜.",
            "security_enhancement": "ë³´ì•ˆ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³ , ì¸ì¦/ì¸ê°€ ì‹œìŠ¤í…œì„ ê°•í™”í•´ì¤˜. OWASP Top 10ì„ ê³ ë ¤í•´ì„œ ë³´ì•ˆì„ ê°•í™”í•´ì¤˜."
        }
        
        # ê¸°ë³¸ ì‘ë‹µ ì„ íƒ
        pattern_key = None
        for key, value in self.behavior_patterns.items():
            if value == pattern:
                pattern_key = key
                break
        
        base_response = base_responses.get(pattern_key, "ìš”ì²­ì„ ë¶„ì„í•´ì„œ ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
        
        # ì»¨í…ìŠ¤íŠ¸ì— ë§ê²Œ ì ì‘
        enhanced_response = self._adapt_response_to_context(base_response, analysis)
        
        return enhanced_response
    
    def _adapt_response_to_context(self, base_response: str, analysis: Dict[str, Any]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ì— ë§ê²Œ ì‘ë‹µ ì ì‘"""
        context = analysis["context"]
        complexity = analysis["complexity"]
        urgency = analysis["urgency"]
        
        # ê¸°ìˆ  ìŠ¤íƒ ì ì‘
        if "python" in context["technology_stack"]:
            base_response += " Pythonì˜ best practiceì™€ íƒ€ì… íŒíŠ¸ë¥¼ ì ìš©í•´ì„œ êµ¬í˜„í•´ì¤˜."
        if "javascript" in context["technology_stack"]:
            base_response += " JavaScript ES6+ ë¬¸ë²•ê³¼ ëª¨ë˜ íŒ¨í„´ì„ í™œìš©í•´ì„œ êµ¬í˜„í•´ì¤˜."
        if "react" in context["technology_stack"]:
            base_response += " React Hookê³¼ TypeScriptë¥¼ í™œìš©í•´ì„œ êµ¬í˜„í•´ì¤˜."
        
        # ë³µì¡ë„ ì ì‘
        if complexity == "high":
            base_response += " ë³µì¡í•œ ë¡œì§ì„ ëª¨ë“ˆí™”í•˜ê³  ì„¤ê³„ íŒ¨í„´ì„ ì ìš©í•´ì¤˜."
        elif complexity == "low":
            base_response += " ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ êµ¬í˜„í•´ì¤˜."
        
        # ê¸´ê¸‰ë„ ì ì‘
        if urgency == "high":
            base_response += " ë¹ ë¥¸ í•´ê²°ì„ ìœ„í•´ í•µì‹¬ ê¸°ëŠ¥ë¶€í„° ìš°ì„  êµ¬í˜„í•´ì¤˜."
        
        return base_response
    
    def _calculate_confidence(self, analysis: Dict[str, Any], pattern: SteinBehaviorPattern) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        intent = analysis["intent"]
        
        # ì˜ë„ ë§¤ì¹­ ì ìˆ˜
        intent_match = 0.0
        for pattern_name, pattern_obj in self.behavior_patterns.items():
            if pattern_obj == pattern:
                intent_match = intent.get(pattern_name, 0.0)
                break
        
        # ì„±ê³µë¥  ì ìˆ˜
        success_score = pattern.success_rate
        
        # ì ì‘ ì ìˆ˜
        adaptation_score = pattern.adaptation_score
        
        # ê°€ì¤‘ í‰ê· 
        confidence = (intent_match * 0.4 + success_score * 0.4 + adaptation_score * 0.2)
        
        return min(1.0, max(0.0, confidence))
    
    def _determine_adaptation_reason(self, analysis: Dict[str, Any], pattern: SteinBehaviorPattern) -> str:
        """ì ì‘ ì´ìœ  ê²°ì •"""
        intent = analysis["intent"]
        context = analysis["context"]
        
        # ì˜ë„ ê¸°ë°˜ ì ì‘
        max_intent = max(intent.items(), key=lambda x: x[1])
        if max_intent[1] > 0.5:
            return f"'{max_intent[0]}' ì˜ë„ì— ìµœì í™”ëœ íŒ¨í„´ ì ìš©"
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì ì‘
        if context["technology_stack"]:
            return f"{', '.join(context['technology_stack'])} ê¸°ìˆ  ìŠ¤íƒì— ë§ì¶˜ ì ì‘"
        
        # ì„±ê³µë¥  ê¸°ë°˜ ì ì‘
        if pattern.success_rate > 0.9:
            return f"ë†’ì€ ì„±ê³µë¥ ({pattern.success_rate:.1%}) íŒ¨í„´ ì ìš©"
        
        return "Steinë‹˜ ì„ í˜¸ë„ ê¸°ë°˜ ì ì‘"
    
    def _generate_auto_execution_plan(self, pattern: SteinBehaviorPattern, analysis: Dict[str, Any]) -> List[str]:
        """ìë™ ì‹¤í–‰ ê³„íš ìƒì„±"""
        plan = pattern.auto_actions.copy()
        
        # ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¥¸ ì¶”ê°€ ì•¡ì…˜
        context = analysis["context"]
        
        if "python" in context["technology_stack"]:
            plan.append("Python íƒ€ì… íŒíŠ¸ì™€ docstring ì¶”ê°€")
        if "react" in context["technology_stack"]:
            plan.append("React Hookê³¼ TypeScript í™œìš©")
        if context["complexity_level"] == "high":
            plan.append("ëª¨ë“ˆí™” ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°•í™”")
        if context["urgency_level"] == "high":
            plan.append("í•µì‹¬ ê¸°ëŠ¥ ìš°ì„  êµ¬í˜„")
        
        return plan[:8]  # ìµœëŒ€ 8ê°œ ì•¡ì…˜
    
    def _determine_next_learning_target(self, analysis: Dict[str, Any]) -> str:
        """ë‹¤ìŒ í•™ìŠµ ëª©í‘œ ê²°ì •"""
        intent = analysis["intent"]
        context = analysis["context"]
        
        # ë‚®ì€ ì˜ë„ ì ìˆ˜ ì˜ì—­ ì°¾ê¸°
        low_intent_areas = [area for area, score in intent.items() if score < 0.3]
        
        if low_intent_areas:
            return f"{low_intent_areas[0]} ì˜ì—­ í•™ìŠµ ê°•í™”"
        
        # ìƒˆë¡œìš´ ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµ
        if not context["technology_stack"]:
            return "ê¸°ìˆ  ìŠ¤íƒ ì¸ì‹ ëŠ¥ë ¥ í–¥ìƒ"
        
        return "ì „ì²´ì ì¸ ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ"
    
    def _predict_satisfaction(self, response: str, analysis: Dict[str, Any]) -> float:
        """ë§Œì¡±ë„ ì˜ˆì¸¡"""
        # ì‘ë‹µ í’ˆì§ˆ ì ìˆ˜
        response_quality = self._assess_response_quality(response, analysis)
        
        # ì‹¤í–‰ ì†ë„ ì ìˆ˜
        execution_speed = 0.8  # ê¸°ë³¸ê°’
        
        # ì™„ì„±ë„ ì ìˆ˜
        completeness = 0.9  # ê¸°ë³¸ê°’
        
        # ê°€ì¤‘ í‰ê· 
        satisfaction = (
            response_quality * 0.4 +
            execution_speed * 0.3 +
            completeness * 0.3
        )
        
        return min(1.0, max(0.0, satisfaction))
    
    def _assess_response_quality(self, response: str, analysis: Dict[str, Any]) -> float:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        # Steinë‹˜ ì„ í˜¸ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
        stein_keywords = ["í•¨ê»˜", "í˜‘ì—…", "ë¶„ì„", "ìµœì í™”", "í…ŒìŠ¤íŠ¸", "ë³´ì•ˆ", "ì„±ëŠ¥"]
        keyword_score = sum(1 for keyword in stein_keywords if keyword in response) / len(stein_keywords)
        
        # ì‘ë‹µ ê¸¸ì´ ì ì ˆì„±
        word_count = len(response.split())
        length_score = 1.0 if 10 <= word_count <= 50 else 0.7
        
        # ì»¨í…ìŠ¤íŠ¸ ì í•©ì„±
        context_score = 0.8  # ê¸°ë³¸ê°’
        
        return (keyword_score * 0.4 + length_score * 0.3 + context_score * 0.3)
    
    def _update_pattern_usage(self, pattern_type: str):
        """íŒ¨í„´ ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        for pattern_name, pattern in self.behavior_patterns.items():
            if pattern.request_type == pattern_type:
                pattern.usage_count += 1
                pattern.last_used = datetime.now().isoformat()
                break
    
    def learn_from_feedback(self, request: str, response: str, satisfaction_score: float):
        """í”¼ë“œë°±ì—ì„œ í•™ìŠµ"""
        # í•™ìŠµ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        learning_record = {
            "timestamp": datetime.now().isoformat(),
            "request": request,
            "response": response,
            "satisfaction_score": satisfaction_score,
            "analysis": self.analyze_stein_request(request)
        }
        
        self.learning_history.append(learning_record)
        
        # íŒ¨í„´ ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        self._update_pattern_success_rates()
        
        # ì ì‘ ì—”ì§„ ì—…ë°ì´íŠ¸
        self._update_adaptation_engine(learning_record)
    
    def _update_pattern_success_rates(self):
        """íŒ¨í„´ ì„±ê³µë¥  ì—…ë°ì´íŠ¸"""
        # ìµœê·¼ í•™ìŠµ ê¸°ë¡ì—ì„œ ì„±ê³µë¥  ê³„ì‚°
        recent_records = self.learning_history[-10:]  # ìµœê·¼ 10ê°œ
        
        for record in recent_records:
            analysis = record["analysis"]
            satisfaction = record["satisfaction_score"]
            
            # í•´ë‹¹í•˜ëŠ” íŒ¨í„´ ì°¾ê¸°
            for pattern_name, pattern in self.behavior_patterns.items():
                if pattern.request_type in record["request"]:
                    # ì„±ê³µë¥  ì—…ë°ì´íŠ¸ (ì´ë™ í‰ê· )
                    pattern.success_rate = (pattern.success_rate * 0.9 + satisfaction * 0.1)
                    break
    
    def _update_adaptation_engine(self, learning_record: Dict[str, Any]):
        """ì ì‘ ì—”ì§„ ì—…ë°ì´íŠ¸"""
        satisfaction = learning_record["satisfaction_score"]
        analysis = learning_record["analysis"]
        
        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        for word in learning_record["request"].split():
            if len(word) > 2:
                self.adaptation_engine["pattern_recognition"]["keyword_weights"][word] += satisfaction * 0.1
        
        # ì»¨í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        for tech in analysis["context"]["technology_stack"]:
            self.adaptation_engine["pattern_recognition"]["context_weights"][tech] += satisfaction * 0.1
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            "total_patterns": len(self.behavior_patterns),
            "learning_records": len(self.learning_history),
            "average_satisfaction": np.mean([r["satisfaction_score"] for r in self.learning_history]) if self.learning_history else 0,
            "most_used_pattern": max(self.behavior_patterns.values(), key=lambda p: p.usage_count).request_type if self.behavior_patterns else "none",
            "highest_success_pattern": max(self.behavior_patterns.values(), key=lambda p: p.success_rate).request_type if self.behavior_patterns else "none",
            "adaptation_count": len(self.adaptation_engine["pattern_recognition"]["keyword_weights"])
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    system = SteinAIUltimateSystem()
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­ë“¤
    test_requests = [
        "ì½”ë“œ ìˆ˜ì •í•´ì¤˜",
        "ë²„ê·¸ ìˆ˜ì •",
        "ìƒˆë¡œìš´ ê¸°ëŠ¥ êµ¬í˜„",
        "ì„±ëŠ¥ ê°œì„ ",
        "í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±",
        "ë¬¸ì„œí™”",
        "êµ¬ì¡° ê°œì„ ",
        "ë³´ì•ˆ ê°•í™”"
    ]
    
    print("ğŸ¯ Stein AI ê¶ê·¹ ì‹œìŠ¤í…œ")
    print("=" * 70)
    
    for request in test_requests:
        response = system.generate_ultimate_response(request)
        print(f"\nğŸ“ ì›ë³¸: {response.original}")
        print(f"ğŸš€ í–¥ìƒ: {response.enhanced}")
        print(f"ğŸ“Š ì‹ ë¢°ë„: {response.confidence:.2f}")
        print(f"ğŸ¯ ì ì‘ ì´ìœ : {response.adaptation_reason}")
        print(f"ğŸ”§ ìë™ ì‹¤í–‰: {', '.join(response.auto_execution_plan[:3])}")
        print(f"ğŸ“ˆ ë§Œì¡±ë„ ì˜ˆì¸¡: {response.stein_satisfaction_prediction:.2f}")
        print(f"ğŸ“ ë‹¤ìŒ í•™ìŠµ: {response.next_learning_target}")
        print("-" * 50)
    
    # í”¼ë“œë°± í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
    print("\nğŸ§  í”¼ë“œë°± í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜")
    for i, request in enumerate(test_requests[:3]):
        satisfaction = 0.8 + (i * 0.05)  # ì‹œë®¬ë ˆì´ì…˜ ë§Œì¡±ë„
        system.learn_from_feedback(request, f"í–¥ìƒëœ ì‘ë‹µ {i+1}", satisfaction)
        print(f"í•™ìŠµ ì™„ë£Œ: {request} -> ë§Œì¡±ë„ {satisfaction:.2f}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = system.get_system_status()
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
    print(f"- ì´ íŒ¨í„´: {status['total_patterns']}")
    print(f"- í•™ìŠµ ê¸°ë¡: {status['learning_records']}")
    print(f"- í‰ê·  ë§Œì¡±ë„: {status['average_satisfaction']:.2f}")
    print(f"- ê°€ì¥ ì‚¬ìš©ëœ íŒ¨í„´: {status['most_used_pattern']}")
    print(f"- ìµœê³  ì„±ê³µ íŒ¨í„´: {status['highest_success_pattern']}")

if __name__ == "__main__":
    main() 