"""
ğŸš€ Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ
Steinë‹˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëª…ë ¹ì–´ë¥¼ ìµœê³  íš¨ìœ¨ì ì¸ AI ì‘ì—…ìœ¼ë¡œ ìë™ ë³€í™˜
"""

import json
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import hashlib
import random
from collections import defaultdict, deque
import logging
import re

# Stein AI ì‹œìŠ¤í…œ import
from stein_ai_ultimate_evolutionary_system import SteinUltimateEvolutionarySystem

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SteinCommand:
    """Steinë‹˜ ëª…ë ¹ì–´ ë°ì´í„°"""
    command_id: str
    original_command: str
    optimized_command: str
    command_type: str
    complexity_level: int
    execution_time: float
    success_rate: float
    user_satisfaction: float
    created_at: datetime
    last_used: datetime
    usage_count: int

@dataclass
class SteinAutomationRule:
    """Stein ìë™í™” ê·œì¹™"""
    rule_id: str
    pattern: str
    transformation: str
    priority: int
    success_rate: float
    usage_count: int
    created_at: datetime
    last_used: datetime

class SteinAutomatedEvolutionSystem:
    """ğŸš€ Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.evolutionary_system = SteinUltimateEvolutionarySystem()
        self.commands: Dict[str, SteinCommand] = {}
        self.automation_rules: Dict[str, SteinAutomationRule] = {}
        self.learning_history: List[Dict] = []
        
        # ëª…ë ¹ì–´ íŒ¨í„´ ì¸ì‹ ì‹œìŠ¤í…œ
        self.command_patterns = {
            'development': [
                r'ê°œë°œ', r'êµ¬í˜„', r'ì½”ë”©', r'í”„ë¡œê·¸ë˜ë°', r'ì•±', r'ì›¹', r'ì‹œìŠ¤í…œ'
            ],
            'analysis': [
                r'ë¶„ì„', r'ê²€í† ', r'í™•ì¸', r'ì ê²€', r'í‰ê°€', r'í…ŒìŠ¤íŠ¸'
            ],
            'optimization': [
                r'ìµœì í™”', r'ê°œì„ ', r'í–¥ìƒ', r'ì§„í™”', r'ì—…ê·¸ë ˆì´ë“œ', r'ì„±ëŠ¥'
            ],
            'creation': [
                r'ìƒì„±', r'ë§Œë“¤', r'ì‘ì„±', r'êµ¬ì¶•', r'ì„¤ê³„', r'ê°œë°œ'
            ],
            'learning': [
                r'í•™ìŠµ', r'ë°°ìš°', r'ì´í•´', r'ì„¤ëª…', r'ê°€ë¥´ì³', r'ì•Œë ¤'
            ]
        }
        
        # ìë™í™” ë³€í™˜ ê·œì¹™
        self.transformation_rules = {
            'simple_request': {
                'patterns': [r'ê°„ë‹¨í•˜ê²Œ', r'ë¹ ë¥´ê²Œ', r'ìš”ì•½'],
                'transformations': [
                    'ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ì ‘ê·¼ë²•ìœ¼ë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”.',
                    'í•µì‹¬ ê¸°ëŠ¥ë§Œ ë¹ ë¥´ê²Œ êµ¬í˜„í•´ì£¼ì„¸ìš”.',
                    'ìš”ì•½ëœ í˜•íƒœë¡œ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.'
                ]
            },
            'detailed_request': {
                'patterns': [r'ìì„¸íˆ', r'ìƒì„¸íˆ', r'ë‹¨ê³„ë³„'],
                'transformations': [
                    'ë‹¨ê³„ë³„ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ê³  êµ¬í˜„í•´ì£¼ì„¸ìš”.',
                    'ëª¨ë“  ê³¼ì •ì„ ìì„¸íˆ ì„¤ëª…í•˜ë©´ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”.',
                    'ìƒì„¸í•œ ë¶„ì„ê³¼ í•¨ê»˜ ì²´ê³„ì ìœ¼ë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”.'
                ]
            },
            'creative_request': {
                'patterns': [r'í˜ì‹ ', r'ì°½ì˜', r'ìƒˆë¡œìš´', r'Steinë‹˜ë‹µê²Œ'],
                'transformations': [
                    'í˜ì‹ ì ì´ê³  ì°½ì˜ì ì¸ ì ‘ê·¼ë²•ìœ¼ë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”.',
                    'Steinë‹˜ë§Œì˜ ë…íŠ¹í•œ ë°©ì‹ìœ¼ë¡œ ê°œë°œí•´ì£¼ì„¸ìš”.',
                    'ìƒˆë¡­ê³  í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.'
                ]
            },
            'quality_request': {
                'patterns': [r'í’ˆì§ˆ', r'ì™„ë²½', r'ì •í™•', r'ê²€ì¦'],
                'transformations': [
                    'ìµœê³  í’ˆì§ˆì˜ ì½”ë“œë¡œ êµ¬í˜„í•˜ê³  ê²€ì¦í•´ì£¼ì„¸ìš”.',
                    'ì™„ë²½í•œ ê¸°ëŠ¥ê³¼ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.',
                    'ì •í™•ì„±ê³¼ ì•ˆì •ì„±ì„ ì¤‘ì‹œí•˜ì—¬ ê°œë°œí•´ì£¼ì„¸ìš”.'
                ]
            },
            'efficiency_request': {
                'patterns': [r'íš¨ìœ¨', r'ì„±ëŠ¥', r'ìµœì í™”', r'ì†ë„'],
                'transformations': [
                    'ìµœê³  íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”.',
                    'ì„±ëŠ¥ ìµœì í™”ë¥¼ ìš°ì„ ìœ¼ë¡œ ê°œë°œí•´ì£¼ì„¸ìš”.',
                    'ë¹ ë¥¸ ì‹¤í–‰ ì†ë„ë¥¼ ì¤‘ì‹œí•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”.'
                ]
            }
        }
        
        logger.info("ğŸš€ Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def analyze_natural_command(self, command: str) -> Dict[str, Any]:
        """ìì—°ìŠ¤ëŸ¬ìš´ ëª…ë ¹ì–´ ë¶„ì„"""
        analysis = {
            'command_type': 'general',
            'complexity_level': 1,
            'priority': 'normal',
            'estimated_time': 5.0,
            'required_skills': [],
            'confidence_score': 0.7
        }
        
        # ëª…ë ¹ì–´ íƒ€ì… ë¶„ì„
        for cmd_type, patterns in self.command_patterns.items():
            for pattern in patterns:
                if re.search(pattern, command, re.IGNORECASE):
                    analysis['command_type'] = cmd_type
                    break
        
        # ë³µì¡ë„ ë ˆë²¨ ë¶„ì„
        complexity_indicators = {
            'high': [r'ë³µì¡', r'ê³ ê¸‰', r'ì „ë¬¸', r'ì‹œìŠ¤í…œ', r'ì•„í‚¤í…ì²˜'],
            'medium': [r'êµ¬í˜„', r'ê°œë°œ', r'ë¶„ì„', r'ì„¤ê³„'],
            'low': [r'ê°„ë‹¨', r'ê¸°ë³¸', r'í™•ì¸', r'í…ŒìŠ¤íŠ¸']
        }
        
        for level, indicators in complexity_indicators.items():
            for indicator in indicators:
                if re.search(indicator, command, re.IGNORECASE):
                    if level == 'high':
                        analysis['complexity_level'] = 3
                    elif level == 'medium':
                        analysis['complexity_level'] = 2
                    else:
                        analysis['complexity_level'] = 1
                    break
        
        # ìš°ì„ ìˆœìœ„ ë¶„ì„
        priority_indicators = {
            'urgent': [r'ê¸´ê¸‰', r'ì¦‰ì‹œ', r'ë°”ë¡œ', r'ì§€ê¸ˆ'],
            'high': [r'ì¤‘ìš”', r'í•„ìˆ˜', r'í•µì‹¬'],
            'normal': [r'ì¼ë°˜', r'ë³´í†µ']
        }
        
        for priority, indicators in priority_indicators.items():
            for indicator in indicators:
                if re.search(indicator, command, re.IGNORECASE):
                    analysis['priority'] = priority
                    break
        
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
        analysis['estimated_time'] = analysis['complexity_level'] * 3.0
        
        # í•„ìš”í•œ ìŠ¤í‚¬ ë¶„ì„
        skill_patterns = {
            'python': [r'íŒŒì´ì¬', r'python', r'ë°ì´í„°', r'ë¶„ì„'],
            'web': [r'ì›¹', r'ì›¹ì‚¬ì´íŠ¸', r'í”„ë¡ íŠ¸ì—”ë“œ', r'ë°±ì—”ë“œ'],
            'ai': [r'AI', r'ì¸ê³µì§€ëŠ¥', r'ë¨¸ì‹ ëŸ¬ë‹', r'ë”¥ëŸ¬ë‹'],
            'database': [r'ë°ì´í„°ë² ì´ìŠ¤', r'DB', r'SQL', r'ì €ì¥'],
            'api': [r'API', r'ì¸í„°í˜ì´ìŠ¤', r'ì—°ë™', r'í†µì‹ ']
        }
        
        for skill, patterns in skill_patterns.items():
            for pattern in patterns:
                if re.search(pattern, command, re.IGNORECASE):
                    analysis['required_skills'].append(skill)
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        analysis['confidence_score'] = min(0.95, 0.5 + len(analysis['required_skills']) * 0.1)
        
        return analysis

    def optimize_command(self, original_command: str, analysis: Dict[str, Any]) -> str:
        """ëª…ë ¹ì–´ ìµœì í™”"""
        optimized_command = original_command
        
        # Stein íŠ¹í™” ì‹œê·¸ë‹ˆì²˜ ë¶„ì„
        stein_signatures = self.evolutionary_system.analyze_stein_signature(original_command)
        
        # ë³€í™˜ ê·œì¹™ ì ìš©
        for rule_name, rule_data in self.transformation_rules.items():
            for pattern in rule_data['patterns']:
                if re.search(pattern, original_command, re.IGNORECASE):
                    # ì ì ˆí•œ ë³€í™˜ ì„ íƒ
                    transformation = random.choice(rule_data['transformations'])
                    optimized_command += f" {transformation}"
                    break
        
        # ë³µì¡ë„ì— ë”°ë¥¸ ì¶”ê°€ ìµœì í™”
        if analysis['complexity_level'] >= 3:
            optimized_command += " ê³ ê¸‰ ê¸°ëŠ¥ê³¼ ìµœì í™”ë¥¼ í¬í•¨í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”."
        elif analysis['complexity_level'] == 2:
            optimized_command += " ì²´ê³„ì ì´ê³  ì•ˆì •ì ì¸ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”."
        else:
            optimized_command += " ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”."
        
        # Stein íŠ¹í™” ìš”ì†Œ ì¶”ê°€
        if stein_signatures['creative_thinking'] > 0.5:
            optimized_command += " Steinë‹˜ì˜ ì°½ì˜ì  ì‚¬ê³ ë¥¼ ë°˜ì˜í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”."
        
        if stein_signatures['efficiency_focus'] > 0.5:
            optimized_command += " ìµœê³ ì˜ íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ì—¬ ê°œë°œí•´ì£¼ì„¸ìš”."
        
        if stein_signatures['quality_orientation'] > 0.5:
            optimized_command += " ìµœê³  í’ˆì§ˆì˜ ì½”ë“œë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”."
        
        return optimized_command

    def create_automation_rule(self, pattern: str, transformation: str, success_rate: float = 0.8) -> SteinAutomationRule:
        """ìë™í™” ê·œì¹™ ìƒì„±"""
        rule_id = f"rule_{len(self.automation_rules) + 1}_{int(time.time())}"
        
        rule = SteinAutomationRule(
            rule_id=rule_id,
            pattern=pattern,
            transformation=transformation,
            priority=1,
            success_rate=success_rate,
            usage_count=0,
            created_at=datetime.now(),
            last_used=datetime.now()
        )
        
        self.automation_rules[rule_id] = rule
        return rule

    def apply_automation_rules(self, command: str) -> str:
        """ìë™í™” ê·œì¹™ ì ìš©"""
        optimized_command = command
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ê·œì¹™ ì ìš©
        sorted_rules = sorted(
            self.automation_rules.values(),
            key=lambda r: (r.priority, r.success_rate),
            reverse=True
        )
        
        for rule in sorted_rules:
            if re.search(rule.pattern, command, re.IGNORECASE):
                optimized_command += f" {rule.transformation}"
                rule.usage_count += 1
                rule.last_used = datetime.now()
                break
        
        return optimized_command

    def learn_from_execution(self, command_id: str, execution_result: Dict[str, Any]):
        """ì‹¤í–‰ ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ"""
        if command_id not in self.commands:
            return
        
        command = self.commands[command_id]
        
        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        if 'success' in execution_result:
            command.success_rate = (command.success_rate * command.usage_count + 
                                 (1.0 if execution_result['success'] else 0.0)) / (command.usage_count + 1)
        
        # ì‹¤í–‰ì‹œê°„ ì—…ë°ì´íŠ¸
        if 'execution_time' in execution_result:
            command.execution_time = execution_result['execution_time']
        
        # ì‚¬ìš©ì ë§Œì¡±ë„ ì—…ë°ì´íŠ¸
        if 'user_satisfaction' in execution_result:
            command.user_satisfaction = execution_result['user_satisfaction']
        
        command.usage_count += 1
        command.last_used = datetime.now()
        
        # í•™ìŠµ íˆìŠ¤í† ë¦¬ ê¸°ë¡
        learning_record = {
            'timestamp': datetime.now(),
            'command_id': command_id,
            'original_command': command.original_command,
            'optimized_command': command.optimized_command,
            'execution_result': execution_result,
            'success_rate': command.success_rate,
            'user_satisfaction': command.user_satisfaction
        }
        
        self.learning_history.append(learning_record)
        
        # ì§„í™” ì‹œìŠ¤í…œì— í”¼ë“œë°± ì „ë‹¬
        self.evolutionary_system.real_time_feedback_processing(execution_result)
        
        logger.info(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: {command_id} - ì„±ê³µë¥ : {command.success_rate:.2f}")

    def evolve_automation_rules(self):
        """ìë™í™” ê·œì¹™ ì§„í™”"""
        # ì„±ê³µë¥ ì´ ë‚®ì€ ê·œì¹™ ì œê±°
        rules_to_remove = []
        for rule_id, rule in self.automation_rules.items():
            if rule.usage_count > 5 and rule.success_rate < 0.3:
                rules_to_remove.append(rule_id)
        
        for rule_id in rules_to_remove:
            del self.automation_rules[rule_id]
            logger.info(f"ğŸ—‘ï¸ ê·œì¹™ ì œê±°: {rule_id} (ë‚®ì€ ì„±ê³µë¥ )")
        
        # ìƒˆë¡œìš´ ê·œì¹™ ìƒì„±
        if len(self.learning_history) > 10:
            self.generate_new_rules_from_learning()

    def generate_new_rules_from_learning(self):
        """í•™ìŠµ íˆìŠ¤í† ë¦¬ì—ì„œ ìƒˆë¡œìš´ ê·œì¹™ ìƒì„±"""
        # ì„±ê³µì ì¸ ëª…ë ¹ì–´ íŒ¨í„´ ë¶„ì„
        successful_commands = [
            record for record in self.learning_history[-20:]
            if record['success_rate'] > 0.8 and record['user_satisfaction'] > 0.8
        ]
        
        if len(successful_commands) < 3:
            return
        
        # ê³µí†µ íŒ¨í„´ ì°¾ê¸°
        common_patterns = self.find_common_patterns(successful_commands)
        
        for pattern, transformation in common_patterns:
            # ì¤‘ë³µ ê·œì¹™ í™•ì¸
            if not any(rule.pattern == pattern for rule in self.automation_rules.values()):
                new_rule = self.create_automation_rule(pattern, transformation, 0.8)
                logger.info(f"ğŸ†• ìƒˆ ê·œì¹™ ìƒì„±: {pattern}")

    def find_common_patterns(self, successful_commands: List[Dict]) -> List[Tuple[str, str]]:
        """ê³µí†µ íŒ¨í„´ ì°¾ê¸°"""
        patterns = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ íŒ¨í„´ ì¶”ì¶œ
        keywords = ['ê°œë°œ', 'êµ¬í˜„', 'ìƒì„±', 'ë¶„ì„', 'ìµœì í™”', 'ê°œì„ ', 'ì„¤ê³„', 'í…ŒìŠ¤íŠ¸']
        
        for keyword in keywords:
            keyword_commands = [
                cmd for cmd in successful_commands
                if keyword in cmd['original_command']
            ]
            
            if len(keyword_commands) >= 2:
                # í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì  ë³€í™˜ ì°¾ê¸°
                best_transformation = self.find_best_transformation(keyword_commands)
                if best_transformation:
                    patterns.append((keyword, best_transformation))
        
        return patterns

    def find_best_transformation(self, commands: List[Dict]) -> Optional[str]:
        """ìµœì  ë³€í™˜ ì°¾ê¸°"""
        if not commands:
            return None
        
        # ê°€ì¥ ë†’ì€ ì„±ê³µë¥ ì„ ê°€ì§„ ëª…ë ¹ì–´ì˜ ë³€í™˜ ì‚¬ìš©
        best_command = max(commands, key=lambda c: c['success_rate'])
        return best_command.get('optimized_command', '')

    def process_natural_command(self, natural_command: str) -> Dict[str, Any]:
        """ìì—°ìŠ¤ëŸ¬ìš´ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        start_time = time.time()
        
        # 1. ëª…ë ¹ì–´ ë¶„ì„
        analysis = self.analyze_natural_command(natural_command)
        
        # 2. ëª…ë ¹ì–´ ìµœì í™”
        optimized_command = self.optimize_command(natural_command, analysis)
        
        # 3. ìë™í™” ê·œì¹™ ì ìš©
        final_command = self.apply_automation_rules(optimized_command)
        
        # 4. ëª…ë ¹ì–´ ì €ì¥
        command_id = f"cmd_{int(time.time())}_{hashlib.md5(natural_command.encode()).hexdigest()[:8]}"
        
        command = SteinCommand(
            command_id=command_id,
            original_command=natural_command,
            optimized_command=final_command,
            command_type=analysis['command_type'],
            complexity_level=analysis['complexity_level'],
            execution_time=time.time() - start_time,
            success_rate=0.7,  # ì´ˆê¸°ê°’
            user_satisfaction=0.7,  # ì´ˆê¸°ê°’
            created_at=datetime.now(),
            last_used=datetime.now(),
            usage_count=0
        )
        
        self.commands[command_id] = command
        
        # 5. ì§„í™” ì‹œìŠ¤í…œì— íŒ¨í„´ ë“±ë¡
        from stein_ai_ultimate_evolutionary_system import SteinPattern
        self.evolutionary_system.patterns[command_id] = SteinPattern(
            pattern_id=command_id,
            command_type=analysis['command_type'],
            success_rate=command.success_rate,
            execution_time=command.execution_time,
            user_satisfaction=command.user_satisfaction,
            complexity_score=analysis['complexity_level'] / 3.0,
            last_used=command.last_used,
            usage_count=command.usage_count,
            evolution_stage=1,
            confidence_score=analysis['confidence_score']
        )
        
        result = {
            'command_id': command_id,
            'original_command': natural_command,
            'optimized_command': final_command,
            'analysis': analysis,
            'execution_time': command.execution_time,
            'estimated_completion_time': analysis['estimated_time']
        }
        
        logger.info(f"ğŸš€ ëª…ë ¹ì–´ ì²˜ë¦¬ ì™„ë£Œ: {command_id}")
        return result

    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            'system_name': 'Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ',
            'status': 'active',
            'total_commands': len(self.commands),
            'total_rules': len(self.automation_rules),
            'learning_records': len(self.learning_history),
            'evolutionary_system_status': self.evolutionary_system.get_system_status(),
            'average_success_rate': sum(cmd.success_rate for cmd in self.commands.values()) / max(len(self.commands), 1),
            'average_user_satisfaction': sum(cmd.user_satisfaction for cmd in self.commands.values()) / max(len(self.commands), 1)
        }

    def save_system_state(self, filename: str = 'stein_automated_evolution_system.json'):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥"""
        system_state = {
            'commands': {cid: asdict(cmd) for cid, cmd in self.commands.items()},
            'automation_rules': {rid: asdict(rule) for rid, rule in self.automation_rules.items()},
            'learning_history': self.learning_history,
            'saved_at': datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(system_state, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ’¾ ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {filename}")

    def load_system_state(self, filename: str = 'stein_automated_evolution_system.json'):
        """ì‹œìŠ¤í…œ ìƒíƒœ ë¡œë“œ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                system_state = json.load(f)
            
            # ëª…ë ¹ì–´ ë³µì›
            self.commands = {}
            for cid, cmd_data in system_state['commands'].items():
                cmd_data['created_at'] = datetime.fromisoformat(cmd_data['created_at'])
                cmd_data['last_used'] = datetime.fromisoformat(cmd_data['last_used'])
                self.commands[cid] = SteinCommand(**cmd_data)
            
            # ìë™í™” ê·œì¹™ ë³µì›
            self.automation_rules = {}
            for rid, rule_data in system_state['automation_rules'].items():
                rule_data['created_at'] = datetime.fromisoformat(rule_data['created_at'])
                rule_data['last_used'] = datetime.fromisoformat(rule_data['last_used'])
                self.automation_rules[rid] = SteinAutomationRule(**rule_data)
            
            # í•™ìŠµ íˆìŠ¤í† ë¦¬ ë³µì›
            self.learning_history = system_state['learning_history']
            
            logger.info(f"ğŸ“‚ ì‹œìŠ¤í…œ ìƒíƒœ ë¡œë“œ ì™„ë£Œ: {filename}")
            
        except FileNotFoundError:
            logger.info(f"ğŸ“‚ ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filename}")

# ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    stein_automation = SteinAutomatedEvolutionSystem()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ë¡œë“œ
    stein_automation.load_system_state()
    
    # ìì—°ìŠ¤ëŸ¬ìš´ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜ˆì‹œ
    natural_commands = [
        "ê°„ë‹¨í•˜ê²Œ ì›¹ì‚¬ì´íŠ¸ ë§Œë“¤ì–´ì¤˜",
        "ìì„¸íˆ AI ì‹œìŠ¤í…œ ë¶„ì„í•´ì¤˜",
        "Steinë‹˜ë‹µê²Œ í˜ì‹ ì ì¸ ì•± ê°œë°œí•´ì¤˜",
        "íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”í•´ì¤˜",
        "í’ˆì§ˆ ë†’ì€ API ì„¤ê³„í•´ì¤˜"
    ]
    
    print("ğŸš€ Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    for i, command in enumerate(natural_commands, 1):
        print(f"\n{i}. ì›ë³¸ ëª…ë ¹ì–´: {command}")
        result = stein_automation.process_natural_command(command)
        print(f"   ìµœì í™”ëœ ëª…ë ¹ì–´: {result['optimized_command']}")
        print(f"   ë¶„ì„ ê²°ê³¼: {result['analysis']['command_type']} (ë³µì¡ë„: {result['analysis']['complexity_level']})")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = stein_automation.get_system_status()
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
    print(f"   ì´ ëª…ë ¹ì–´ ìˆ˜: {status['total_commands']}")
    print(f"   ì´ ê·œì¹™ ìˆ˜: {status['total_rules']}")
    print(f"   í‰ê·  ì„±ê³µë¥ : {status['average_success_rate']:.2f}")
    print(f"   í‰ê·  ì‚¬ìš©ì ë§Œì¡±ë„: {status['average_user_satisfaction']:.2f}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥
    stein_automation.save_system_state()
    
    print("\nâœ¨ Stein AI ì™„ì „ ìë™í™” ì§„í™” ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!") 