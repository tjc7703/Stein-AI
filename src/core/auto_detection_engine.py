"""
ğŸ¤– Stein AI ìë™ íŒë³„ ë° ë§¥ë½ ì¶”ë¡  ì—”ì§„
ì§ˆë¬¸ ì˜ë„ ë¶„ì„, ìš°ì„ ìˆœìœ„ ì˜ˆì¸¡, ìƒí™© ì´í•´ ì‹œìŠ¤í…œ
"""

import re
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import asyncio

class QuestionIntent(Enum):
    """ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜"""
    LEARNING = "learning"           # í•™ìŠµ ëª©ì 
    PROBLEM_SOLVING = "problem_solving"  # ë¬¸ì œ í•´ê²°
    IMPLEMENTATION = "implementation"    # êµ¬í˜„ ìš”ì²­
    OPTIMIZATION = "optimization"       # ìµœì í™”
    COMPARISON = "comparison"          # ë¹„êµ ë¶„ì„
    DEBUGGING = "debugging"           # ë””ë²„ê¹…
    ARCHITECTURE = "architecture"     # ì•„í‚¤í…ì²˜ ì„¤ê³„
    BEST_PRACTICE = "best_practice"   # ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

class UrgencyLevel(Enum):
    """ê¸´ê¸‰ë„ ìˆ˜ì¤€"""
    CRITICAL = "critical"    # ì¦‰ì‹œ ì²˜ë¦¬ í•„ìš”
    HIGH = "high"           # ë†’ì€ ìš°ì„ ìˆœìœ„
    MEDIUM = "medium"       # ë³´í†µ ìš°ì„ ìˆœìœ„
    LOW = "low"            # ë‚®ì€ ìš°ì„ ìˆœìœ„

class ComplexityLevel(Enum):
    """ë³µì¡ë„ ìˆ˜ì¤€"""
    SIMPLE = "simple"       # ê°„ë‹¨í•œ ì§ˆë¬¸
    MODERATE = "moderate"   # ë³´í†µ ë³µì¡ë„
    COMPLEX = "complex"     # ë³µì¡í•œ ì§ˆë¬¸
    EXPERT = "expert"      # ì „ë¬¸ê°€ ìˆ˜ì¤€

@dataclass
class ContextualInfo:
    """ë§¥ë½ ì •ë³´"""
    time_context: str      # ì‹œê°„ì  ë§¥ë½
    project_context: str   # í”„ë¡œì íŠ¸ ë§¥ë½
    tech_context: List[str]  # ê¸°ìˆ ì  ë§¥ë½
    user_mood: str         # ì‚¬ìš©ì ê°ì • ìƒíƒœ
    session_history: List[str]  # ì„¸ì…˜ íˆìŠ¤í† ë¦¬

@dataclass
class AutoDetectionResult:
    """ìë™ íŒë³„ ê²°ê³¼"""
    intent: QuestionIntent
    urgency: UrgencyLevel
    complexity: ComplexityLevel
    priority_score: float  # 0-100ì 
    context: ContextualInfo
    reasoning: str         # íŒë³„ ê·¼ê±°
    suggested_approach: str  # ì œì•ˆí•˜ëŠ” ì ‘ê·¼ ë°©ë²•
    estimated_time: str    # ì˜ˆìƒ ì†Œìš” ì‹œê°„

class SteinContextualReasoningEngine:
    """Stein AI ë§¥ë½ ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self):
        self.intent_patterns = {
            QuestionIntent.LEARNING: [
                r"(í•™ìŠµ|ë°°ìš°|ì´í•´|ì•Œê³ |ì„¤ëª…|ì›ë¦¬|ê°œë…|ê¸°ì´ˆ)",
                r"(ì–´ë–»ê²Œ.*ì‘ë™|ì™œ.*í•„ìš”|ë¬´ì—‡.*ì˜ë¯¸)"
            ],
            QuestionIntent.PROBLEM_SOLVING: [
                r"(ë¬¸ì œ|ì—ëŸ¬|ì˜¤ë¥˜|ì•ˆë¨|ì‹¤íŒ¨|í•´ê²°|ê³ ì¹˜)",
                r"(ë²„ê·¸|ì´ìƒ|ì‘ë™í•˜ì§€|ì•ˆí•´|ë§‰í˜)"
            ],
            QuestionIntent.IMPLEMENTATION: [
                r"(êµ¬í˜„|ë§Œë“¤|ìƒì„±|ê°œë°œ|ì½”ë”©|ì‘ì„±)",
                r"(ì¶”ê°€|ë„£ê³ |ê¸°ëŠ¥|ëª¨ë“ˆ|ì»´í¬ë„ŒíŠ¸)"
            ],
            QuestionIntent.OPTIMIZATION: [
                r"(ìµœì í™”|ì„±ëŠ¥|ë¹ ë¥´ê²Œ|íš¨ìœ¨|ê°œì„ |í–¥ìƒ)",
                r"(ì†ë„|ë©”ëª¨ë¦¬|ë¦¬íŒ©í† ë§|íŠœë‹)"
            ],
            QuestionIntent.COMPARISON: [
                r"(ë¹„êµ|ì°¨ì´|vs|ëŒ€ì‹ |ì„ íƒ|ì–´ë–¤.*ì¢‹)",
                r"(ì¥ë‹¨ì |pros.*cons|better|worse)"
            ],
            QuestionIntent.DEBUGGING: [
                r"(ë””ë²„ê·¸|ë””ë²„ê¹…|ì°¾ê¸°|ì›ì¸|ì™œ.*ì•ˆ)",
                r"(ë¡œê·¸|ì¶”ì |ê²€ì‚¬|í™•ì¸)"
            ],
            QuestionIntent.ARCHITECTURE: [
                r"(ì•„í‚¤í…ì²˜|ì„¤ê³„|êµ¬ì¡°|íŒ¨í„´|ì‹œìŠ¤í…œ)",
                r"(ëª¨ë¸ë§|ë””ìì¸|í”„ë ˆì„ì›Œí¬|êµ¬ì„±)"
            ],
            QuestionIntent.BEST_PRACTICE: [
                r"(ë² ìŠ¤íŠ¸.*í”„ë™í‹°ìŠ¤|ê°€ì´ë“œë¼ì¸|ê·œì¹™|í‘œì¤€)",
                r"(ì˜¬ë°”ë¥¸.*ë°©ë²•|ê¶Œì¥|ì¶”ì²œ.*ë°©ì‹)"
            ]
        }
        
        self.urgency_indicators = {
            UrgencyLevel.CRITICAL: [
                r"(ê¸´ê¸‰|ì¦‰ì‹œ|ë¹¨ë¦¬|ê¸‰í•´|ë§ˆê°|deadline)",
                r"(ì„œë²„.*ë‹¤ìš´|ì¥ì• |critical|emergency)"
            ],
            UrgencyLevel.HIGH: [
                r"(ì¤‘ìš”|ìš°ì„ |ë¨¼ì €|ì‹œê¸‰|í•„ìˆ˜)",
                r"(í”„ë¡œë•ì…˜|ë¼ì´ë¸Œ|production|live)"
            ],
            UrgencyLevel.MEDIUM: [
                r"(ë³´í†µ|ì¼ë°˜|í‰ì†Œ|ë•Œ|when)",
                r"(ê°œë°œ|í…ŒìŠ¤íŠ¸|development|test)"
            ],
            UrgencyLevel.LOW: [
                r"(ë‚˜ì¤‘ì—|ì—¬ìœ |ì‹œê°„.*ë‚ ë•Œ|ê¶ê¸ˆ)",
                r"(ì°¸ê³ |reference|leisure|curious)"
            ]
        }
        
        self.complexity_indicators = {
            ComplexityLevel.SIMPLE: [
                r"(ê°„ë‹¨|ì‰¬ìš´|ê¸°ë³¸|basic|simple)",
                r"(ì‹œì‘|ì²˜ìŒ|ì´ˆë³´|begin)"
            ],
            ComplexityLevel.MODERATE: [
                r"(ë³´í†µ|ì¼ë°˜|medium|moderate)",
                r"(ì¤‘ê¸‰|intermediate|standard)"
            ],
            ComplexityLevel.COMPLEX: [
                r"(ë³µì¡|ì–´ë ¤ìš´|ê³ ê¸‰|complex|advanced)",
                r"(ìƒì„¸|detail|comprehensive)"
            ],
            ComplexityLevel.EXPERT: [
                r"(ì „ë¬¸ê°€|expert|professional|master)",
                r"(ì‹¬í™”|deep.*dive|architecture.*level)"
            ]
        }
        
        # Steinë‹˜ì˜ íŒ¨í„´ í•™ìŠµ ë°ì´í„°
        self.stein_patterns = {
            "preferred_tech": ["Python", "FastAPI", "React", "TypeScript", "AI/ML"],
            "communication_style": "detail_oriented",
            "learning_preference": "hands_on_with_theory",
            "question_evolution": "meta_cognitive",  # ë©”íƒ€ì¸ì§€ì  ì„±í–¥
            "priority_tendency": "innovation_first"  # í˜ì‹  ìš°ì„ 
        }

    def analyze_context(self, question: str, session_history: List[str] = None) -> ContextualInfo:
        """ë§¥ë½ ì •ë³´ ë¶„ì„"""
        
        # ì‹œê°„ì  ë§¥ë½ ë¶„ì„
        time_context = self._analyze_time_context(question)
        
        # í”„ë¡œì íŠ¸ ë§¥ë½ ë¶„ì„
        project_context = self._analyze_project_context(question)
        
        # ê¸°ìˆ ì  ë§¥ë½ ë¶„ì„
        tech_context = self._analyze_tech_context(question)
        
        # ì‚¬ìš©ì ê°ì • ìƒíƒœ ë¶„ì„
        user_mood = self._analyze_user_mood(question)
        
        return ContextualInfo(
            time_context=time_context,
            project_context=project_context,
            tech_context=tech_context,
            user_mood=user_mood,
            session_history=session_history or []
        )

    def _analyze_time_context(self, question: str) -> str:
        """ì‹œê°„ì  ë§¥ë½ ë¶„ì„"""
        if re.search(r"(ì§€ê¸ˆ|í˜„ì¬|today|now)", question, re.IGNORECASE):
            return "immediate"
        elif re.search(r"(ë‹¤ìŒ|next|í–¥í›„|future)", question, re.IGNORECASE):
            return "future_planning"
        elif re.search(r"(ì´ì „|ê³¼ê±°|before|past)", question, re.IGNORECASE):
            return "retrospective"
        else:
            return "general"

    def _analyze_project_context(self, question: str) -> str:
        """í”„ë¡œì íŠ¸ ë§¥ë½ ë¶„ì„"""
        if re.search(r"(Stein|stein)", question, re.IGNORECASE):
            return "stein_ai_project"
        elif re.search(r"(í”„ë¡œì íŠ¸|project)", question, re.IGNORECASE):
            return "current_project"
        elif re.search(r"(ì‹œìŠ¤í…œ|system|í”Œë«í¼|platform)", question, re.IGNORECASE):
            return "system_development"
        else:
            return "general_development"

    def _analyze_tech_context(self, question: str) -> List[str]:
        """ê¸°ìˆ ì  ë§¥ë½ ë¶„ì„"""
        tech_stack = []
        
        for tech in self.stein_patterns["preferred_tech"]:
            if tech.lower() in question.lower():
                tech_stack.append(tech)
        
        # ì¶”ê°€ ê¸°ìˆ  ìŠ¤íƒ ê°ì§€
        additional_tech = {
            "database": ["ë°ì´í„°ë² ì´ìŠ¤", "DB", "PostgreSQL", "MongoDB"],
            "frontend": ["í”„ë¡ íŠ¸ì—”ë“œ", "UI", "UX", "ì›¹"],
            "backend": ["ë°±ì—”ë“œ", "ì„œë²„", "API"],
            "mobile": ["ëª¨ë°”ì¼", "ì•±", "iOS", "Android"],
            "ai_ml": ["AI", "ML", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹"]
        }
        
        for category, keywords in additional_tech.items():
            if any(keyword.lower() in question.lower() for keyword in keywords):
                tech_stack.append(category)
        
        return tech_stack

    def _analyze_user_mood(self, question: str) -> str:
        """ì‚¬ìš©ì ê°ì • ìƒíƒœ ë¶„ì„"""
        if re.search(r"(ê³ ë§™|ê°ì‚¬|please|ë¶€íƒ)", question, re.IGNORECASE):
            return "polite"
        elif re.search(r"(ê¸´ê¸‰|ê¸‰í•´|ë¹¨ë¦¬|help)", question, re.IGNORECASE):
            return "urgent"
        elif re.search(r"(ê¶ê¸ˆ|curious|wonder)", question, re.IGNORECASE):
            return "curious"
        elif re.search(r"(ë§‰í˜|ì–´ë µ|í˜ë“¤|stuck)", question, re.IGNORECASE):
            return "frustrated"
        elif re.search(r"(ì¢‹ì€|í›Œë¥­|excellent|great)", question, re.IGNORECASE):
            return "positive"
        else:
            return "neutral"

    def detect_intent_and_priority(self, question: str, context: ContextualInfo) -> AutoDetectionResult:
        """ì§ˆë¬¸ ì˜ë„ ë° ìš°ì„ ìˆœìœ„ ìë™ ê°ì§€"""
        
        # 1. ì˜ë„ ë¶„ì„
        intent = self._detect_intent(question)
        
        # 2. ê¸´ê¸‰ë„ ë¶„ì„
        urgency = self._detect_urgency(question, context)
        
        # 3. ë³µì¡ë„ ë¶„ì„
        complexity = self._detect_complexity(question, context)
        
        # 4. ì¢…í•© ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        priority_score = self._calculate_priority_score(intent, urgency, complexity, context)
        
        # 5. ì¶”ë¡  ê·¼ê±° ìƒì„±
        reasoning = self._generate_reasoning(intent, urgency, complexity, context)
        
        # 6. ì œì•ˆ ì ‘ê·¼ë²• ìƒì„±
        suggested_approach = self._suggest_approach(intent, urgency, complexity, context)
        
        # 7. ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚°
        estimated_time = self._estimate_time(complexity, intent)
        
        return AutoDetectionResult(
            intent=intent,
            urgency=urgency,
            complexity=complexity,
            priority_score=priority_score,
            context=context,
            reasoning=reasoning,
            suggested_approach=suggested_approach,
            estimated_time=estimated_time
        )

    def _detect_intent(self, question: str) -> QuestionIntent:
        """ì§ˆë¬¸ ì˜ë„ ê°ì§€"""
        scores = {}
        
        for intent, patterns in self.intent_patterns.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, question, re.IGNORECASE))
                score += matches
            scores[intent] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ë°˜í™˜
        if max(scores.values()) == 0:
            return QuestionIntent.LEARNING  # ê¸°ë³¸ê°’
        
        return max(scores, key=scores.get)

    def _detect_urgency(self, question: str, context: ContextualInfo) -> UrgencyLevel:
        """ê¸´ê¸‰ë„ ê°ì§€"""
        scores = {}
        
        for urgency, patterns in self.urgency_indicators.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, question, re.IGNORECASE))
                score += matches
            scores[urgency] = score
        
        # ë§¥ë½ ê¸°ë°˜ ì¡°ì •
        if context.user_mood == "urgent":
            scores[UrgencyLevel.HIGH] += 2
        elif context.user_mood == "frustrated":
            scores[UrgencyLevel.HIGH] += 1
        
        if context.project_context == "stein_ai_project":
            scores[UrgencyLevel.HIGH] += 1  # Stein í”„ë¡œì íŠ¸ëŠ” ìš°ì„ ìˆœìœ„
        
        if max(scores.values()) == 0:
            return UrgencyLevel.MEDIUM  # ê¸°ë³¸ê°’
        
        return max(scores, key=scores.get)

    def _detect_complexity(self, question: str, context: ContextualInfo) -> ComplexityLevel:
        """ë³µì¡ë„ ê°ì§€"""
        scores = {}
        
        for complexity, patterns in self.complexity_indicators.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, question, re.IGNORECASE))
                score += matches
            scores[complexity] = score
        
        # ê¸°ìˆ  ìŠ¤íƒ ê°œìˆ˜ë¡œ ë³µì¡ë„ ì¡°ì •
        tech_count = len(context.tech_context)
        if tech_count >= 3:
            scores[ComplexityLevel.COMPLEX] += 2
        elif tech_count >= 2:
            scores[ComplexityLevel.MODERATE] += 1
        
        # ì§ˆë¬¸ ê¸¸ì´ë¡œ ë³µì¡ë„ ì¡°ì •
        if len(question) > 200:
            scores[ComplexityLevel.COMPLEX] += 1
        elif len(question) > 100:
            scores[ComplexityLevel.MODERATE] += 1
        
        if max(scores.values()) == 0:
            return ComplexityLevel.MODERATE  # ê¸°ë³¸ê°’
        
        return max(scores, key=scores.get)

    def _calculate_priority_score(self, intent: QuestionIntent, urgency: UrgencyLevel, 
                                 complexity: ComplexityLevel, context: ContextualInfo) -> float:
        """ì¢…í•© ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚° (0-100ì )"""
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 50.0
        
        # ê¸´ê¸‰ë„ ê°€ì¤‘ì¹˜
        urgency_weights = {
            UrgencyLevel.CRITICAL: 40,
            UrgencyLevel.HIGH: 25,
            UrgencyLevel.MEDIUM: 10,
            UrgencyLevel.LOW: -10
        }
        
        # ì˜ë„ë³„ ê°€ì¤‘ì¹˜ (Steinë‹˜ ì„±í–¥ ë°˜ì˜)
        intent_weights = {
            QuestionIntent.LEARNING: 15,      # í•™ìŠµ ì¤‘ì‹œ
            QuestionIntent.IMPLEMENTATION: 20, # êµ¬í˜„ ì¤‘ì‹œ
            QuestionIntent.OPTIMIZATION: 18,   # ìµœì í™” ì¤‘ì‹œ
            QuestionIntent.ARCHITECTURE: 17,   # ì•„í‚¤í…ì²˜ ì¤‘ì‹œ
            QuestionIntent.PROBLEM_SOLVING: 25, # ë¬¸ì œí•´ê²° ìµœìš°ì„ 
            QuestionIntent.COMPARISON: 12,
            QuestionIntent.DEBUGGING: 20,
            QuestionIntent.BEST_PRACTICE: 15
        }
        
        # ë³µì¡ë„ ê°€ì¤‘ì¹˜ (ë³µì¡í• ìˆ˜ë¡ ë” í¥ë¯¸ë¡œì›Œí•¨)
        complexity_weights = {
            ComplexityLevel.EXPERT: 15,
            ComplexityLevel.COMPLEX: 10,
            ComplexityLevel.MODERATE: 5,
            ComplexityLevel.SIMPLE: 0
        }
        
        # ì ìˆ˜ ê³„ì‚°
        score = base_score
        score += urgency_weights.get(urgency, 0)
        score += intent_weights.get(intent, 0)
        score += complexity_weights.get(complexity, 0)
        
        # ë§¥ë½ ê¸°ë°˜ ì¶”ê°€ ì¡°ì •
        if context.project_context == "stein_ai_project":
            score += 10  # Stein í”„ë¡œì íŠ¸ ìš°ì„ 
        
        if "AI" in context.tech_context or "ML" in context.tech_context:
            score += 8   # AI/ML ê´€ë ¨ ìš°ì„ 
        
        if context.user_mood == "curious":
            score += 5   # í˜¸ê¸°ì‹¬ ì¥ë ¤
        
        return max(0.0, min(100.0, score))

    def _generate_reasoning(self, intent: QuestionIntent, urgency: UrgencyLevel, 
                          complexity: ComplexityLevel, context: ContextualInfo) -> str:
        """íŒë³„ ê·¼ê±° ìƒì„±"""
        reasoning_parts = []
        
        # ì˜ë„ ê·¼ê±°
        intent_reasons = {
            QuestionIntent.LEARNING: "í•™ìŠµ ëª©ì ì˜ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤",
            QuestionIntent.PROBLEM_SOLVING: "ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤",
            QuestionIntent.IMPLEMENTATION: "êµ¬í˜„ ìš”ì²­ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤",
            QuestionIntent.OPTIMIZATION: "ì„±ëŠ¥ ìµœì í™” ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤",
            QuestionIntent.COMPARISON: "ë¹„êµ ë¶„ì„ì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤",
            QuestionIntent.DEBUGGING: "ë””ë²„ê¹… ì§€ì›ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤",
            QuestionIntent.ARCHITECTURE: "ì‹œìŠ¤í…œ ì„¤ê³„ ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤",
            QuestionIntent.BEST_PRACTICE: "ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¡°ì–¸ì„ êµ¬í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤"
        }
        reasoning_parts.append(intent_reasons.get(intent, "ì¼ë°˜ì ì¸ ì§ˆë¬¸ì…ë‹ˆë‹¤"))
        
        # ê¸´ê¸‰ë„ ê·¼ê±°
        if urgency == UrgencyLevel.CRITICAL:
            reasoning_parts.append("ì¦‰ì‹œ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê¸´ê¸‰í•œ ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤")
        elif urgency == UrgencyLevel.HIGH:
            reasoning_parts.append("ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì²˜ë¦¬í•´ì•¼ í•  ì¤‘ìš”í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤")
        
        # ë³µì¡ë„ ê·¼ê±°
        if complexity == ComplexityLevel.EXPERT:
            reasoning_parts.append("ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê¹Šì´ ìˆëŠ” ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤")
        elif complexity == ComplexityLevel.COMPLEX:
            reasoning_parts.append("ë³µí•©ì ì¸ ìš”ì†Œë“¤ì„ ê³ ë ¤í•œ ìƒì„¸í•œ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë§¥ë½ ê·¼ê±°
        if context.project_context == "stein_ai_project":
            reasoning_parts.append("Stein AI í”„ë¡œì íŠ¸ì™€ ì§ì ‘ ê´€ë ¨ëœ ì§ˆë¬¸ì…ë‹ˆë‹¤")
        
        if context.tech_context:
            tech_list = ", ".join(context.tech_context)
            reasoning_parts.append(f"ë‹¤ìŒ ê¸°ìˆ ë“¤ì´ ê´€ë ¨ë©ë‹ˆë‹¤: {tech_list}")
        
        return ". ".join(reasoning_parts) + "."

    def _suggest_approach(self, intent: QuestionIntent, urgency: UrgencyLevel, 
                         complexity: ComplexityLevel, context: ContextualInfo) -> str:
        """ì œì•ˆí•˜ëŠ” ì ‘ê·¼ ë°©ë²•"""
        
        approach_suggestions = {
            QuestionIntent.LEARNING: "ë‹¨ê³„ë³„ ì„¤ëª…ê³¼ ì‹¤ìŠµ ì˜ˆì œë¥¼ í¬í•¨í•œ í•™ìŠµ ìë£Œ ì œê³µ",
            QuestionIntent.PROBLEM_SOLVING: "ë¬¸ì œ ë¶„ì„ â†’ í•´ê²°ì±… ì œì‹œ â†’ ê²€ì¦ ë°©ë²• ì•ˆë‚´",
            QuestionIntent.IMPLEMENTATION: "ìš”êµ¬ì‚¬í•­ ë¶„ì„ â†’ ì„¤ê³„ â†’ ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ",
            QuestionIntent.OPTIMIZATION: "í˜„ì¬ ìƒíƒœ ë¶„ì„ â†’ ë³‘ëª©ì  ì‹ë³„ â†’ ìµœì í™” ë°©ì•ˆ ì œì‹œ",
            QuestionIntent.COMPARISON: "ë‹¤ê°ë„ ë¹„êµ ë¶„ì„ â†’ ì¥ë‹¨ì  ì •ë¦¬ â†’ ìƒí™©ë³„ ì¶”ì²œ",
            QuestionIntent.DEBUGGING: "ë¬¸ì œ ì¬í˜„ â†’ ì›ì¸ ë¶„ì„ â†’ í•´ê²°ì±… ì œì‹œ â†’ ì˜ˆë°©ë²• ì•ˆë‚´",
            QuestionIntent.ARCHITECTURE: "ìš”êµ¬ì‚¬í•­ ì •ì˜ â†’ ì•„í‚¤í…ì²˜ ì„¤ê³„ â†’ êµ¬í˜„ ì „ëµ",
            QuestionIntent.BEST_PRACTICE: "ì—…ê³„ í‘œì¤€ ì†Œê°œ â†’ ì‹¤ë¬´ ì ìš© ë°©ë²• â†’ ì£¼ì˜ì‚¬í•­"
        }
        
        base_approach = approach_suggestions.get(intent, "ì§ˆë¬¸ ë¶„ì„ í›„ ë§ì¶¤í˜• ë‹µë³€ ì œê³µ")
        
        # ê¸´ê¸‰ë„ì— ë”°ë¥¸ ì ‘ê·¼ë²• ì¡°ì •
        if urgency == UrgencyLevel.CRITICAL:
            return f"ğŸš¨ ê¸´ê¸‰ ì²˜ë¦¬: {base_approach}"
        elif urgency == UrgencyLevel.HIGH:
            return f"âš¡ ìš°ì„  ì²˜ë¦¬: {base_approach}"
        
        # ë³µì¡ë„ì— ë”°ë¥¸ ì ‘ê·¼ë²• ì¡°ì •
        if complexity == ComplexityLevel.EXPERT:
            return f"ğŸ“ ì „ë¬¸ê°€ ìˆ˜ì¤€: {base_approach} + ê³ ê¸‰ ê°œë… ë° ì‹¬í™” ë¶„ì„"
        elif complexity == ComplexityLevel.SIMPLE:
            return f"ğŸ“š ê¸°ì´ˆ ìˆ˜ì¤€: {base_approach} + ì¹œì ˆí•œ ì„¤ëª…"
        
        return base_approach

    def _estimate_time(self, complexity: ComplexityLevel, intent: QuestionIntent) -> str:
        """ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚°"""
        
        base_times = {
            ComplexityLevel.SIMPLE: 2,      # 2ë¶„
            ComplexityLevel.MODERATE: 5,    # 5ë¶„
            ComplexityLevel.COMPLEX: 15,    # 15ë¶„
            ComplexityLevel.EXPERT: 30      # 30ë¶„
        }
        
        intent_multipliers = {
            QuestionIntent.LEARNING: 1.2,
            QuestionIntent.IMPLEMENTATION: 1.5,
            QuestionIntent.ARCHITECTURE: 1.8,
            QuestionIntent.COMPARISON: 1.3,
            QuestionIntent.PROBLEM_SOLVING: 1.0,
            QuestionIntent.DEBUGGING: 1.1,
            QuestionIntent.OPTIMIZATION: 1.4,
            QuestionIntent.BEST_PRACTICE: 1.1
        }
        
        base_time = base_times.get(complexity, 5)
        multiplier = intent_multipliers.get(intent, 1.0)
        
        estimated_minutes = int(base_time * multiplier)
        
        if estimated_minutes < 5:
            return f"{estimated_minutes}ë¶„ ë‚´"
        elif estimated_minutes < 60:
            return f"ì•½ {estimated_minutes}ë¶„"
        else:
            hours = estimated_minutes // 60
            minutes = estimated_minutes % 60
            return f"ì•½ {hours}ì‹œê°„ {minutes}ë¶„"

# ğŸš€ Stein AI ìë™ íŒë³„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
stein_auto_detector = SteinContextualReasoningEngine()

async def analyze_question_automatically(question: str, session_history: List[str] = None) -> AutoDetectionResult:
    """ì§ˆë¬¸ ìë™ ë¶„ì„ í•¨ìˆ˜"""
    
    # ë§¥ë½ ë¶„ì„
    context = stein_auto_detector.analyze_context(question, session_history)
    
    # ì˜ë„ ë° ìš°ì„ ìˆœìœ„ ê°ì§€
    result = stein_auto_detector.detect_intent_and_priority(question, context)
    
    return result

def get_stein_personalized_response(result: AutoDetectionResult) -> Dict[str, Any]:
    """Steinë‹˜ ë§ì¶¤í˜• ì‘ë‹µ ìƒì„±"""
    
    return {
        "auto_analysis": {
            "intent": result.intent.value,
            "urgency": result.urgency.value,
            "complexity": result.complexity.value,
            "priority_score": result.priority_score,
            "estimated_time": result.estimated_time
        },
        "context_understanding": {
            "time_context": result.context.time_context,
            "project_context": result.context.project_context,
            "tech_context": result.context.tech_context,
            "user_mood": result.context.user_mood
        },
        "ai_reasoning": result.reasoning,
        "suggested_approach": result.suggested_approach,
        "stein_optimization": {
            "priority_explanation": f"ìš°ì„ ìˆœìœ„ {result.priority_score:.1f}ì  - {result.urgency.value} ê¸´ê¸‰ë„, {result.complexity.value} ë³µì¡ë„",
            "personalized_note": f"Steinë‹˜ì˜ {result.intent.value} ì„±í–¥ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤",
            "learning_integration": "ì´ ì§ˆë¬¸ì€ Stein AI ê°œì¸í™” í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©ë©ë‹ˆë‹¤"
        }
    } 